2023-06-02 11:06:48.892 | INFO     | __main__:main:57 - Load config from configs/neo_small.yaml
2023-06-02 11:06:48.893 | INFO     | __main__:main:58 - {'dataset': {'data_path': '/root/neo_code_reco/bkai-igh-neopolyp', 'train_data_path': ['/root/neo_code_reco/bkai-igh-neopolyp'], 'test_data_path': ['/root/neo_code/bkai-igh-neopolyp/test/test'], 'val_data_path': ['/root/neo_code_reco/bkai-igh-neopolyp']}, 'model': {'num_classes': 3, 'save_dir': '/root/neo_code_reco/configs/checkpoint', 'backbone': 'MiT-B3', 'head': 'FaPNHead', 'pretrained': 'mit_b3.pth'}, 'optimizer': {'name': 'adam', 'lr': 0.0001, 'clip': 0.5, 'scheduler': 'cosine_warmup', 'loss': 'multi_structure_loss'}, 'dev': 'cuda', 'train': {'start_from': 0, 'save_from': 99, 'num_epochs': 100, 'num_warmup_epoch': 8, 'is_val': False, 'size_rates': [0.75, 1, 1.25], 'dataloader': {'batchsize': 8, 'img_size': 384, 'shuffle': True, 'num_workers': 4, 'pin_memory': True, 'drop_last': True}, 'amp': False, 'ddp': False, 'augment': {'prob': 1, 'Flip_prob': 0.5, 'HueSaturationValue_prob': 0.5, 'RandomBrightnessContrast_prob': 0.5, 'crop_prob': 0.0, 'randomrotate90_prob': 0.5, 'ColorJitter_prob': 0.5}, 'augment_weak': {'prob': 1, 'Flip_prob': 0.5}}, 'val': {'dataloader': {'batchsize': 8, 'img_size': 384, 'shuffle': True, 'num_workers': 4, 'pin_memory': True, 'drop_last': False}}, 'test': {'dev': 'cuda', 'visualize': True, 'visualize_dir': '/root/neo_code_reco/neo_visualize', 'vis_x': 180, 'vis_overwrite': False, 'checkpoint_dir': '/root/neo_code_reco/configs/checkpoint/MiT-B3-FaPNHead_100.pth', 'dataloader': {'batchsize': 1, 'img_size': 384, 'shuffle': True, 'num_workers': 4, 'pin_memory': True, 'drop_last': False}, 'augment': {'prob': 1, 'Flip_prob': 0, 'HueSaturationValue_prob': 0, 'RandomBrightnessContrast_prob': 0, 'crop_prob': 0, 'randomrotate90_prob': 0, 'elastictransform_prob': 0, 'gridistortion_prob': 0, 'opticaldistortion_prob': 0, 'verticalflip_prob': 0, 'horizontalflip_prob': 0, 'randomgamma_prob': 0, 'CoarseDropout_prob': 0, 'RGBShift_prob': 0, 'MotionBlur_prob': 0, 'MedianBlur_prob': 0, 'GaussianBlur_prob': 0, 'GaussNoise_prob': 0, 'ChannelShuffle_prob': 0}}}
2023-06-02 11:06:48.893 | INFO     | __main__:main:59 - Getting datapath
2023-06-02 11:06:48.901 | INFO     | __main__:main:74 - There are 1000 images to train
2023-06-02 11:06:48.901 | INFO     | __main__:main:93 - Train model with no valid dataset
2023-06-02 11:06:48.902 | INFO     | __main__:main:95 - Loading data
2023-06-02 11:06:49.335 | INFO     | __main__:main:112 - 125 batches to train
2023-06-02 11:06:49.336 | INFO     | __main__:main:125 - Loading model
2023-06-02 11:06:49.336 | INFO     | __main__:main:146 - Loading checkpoint from mit_b3.pth ...
2023-06-02 11:06:55.418 | INFO     | __main__:main:190 - Training with FP32 ...
2023-06-02 11:12:15.627 | INFO     | trainer:train_loop:183 - Epoch: [1/ 100] | Train loss: [2.2023627071380614]
2023-06-02 11:17:32.437 | INFO     | trainer:train_loop:183 - Epoch: [2/ 100] | Train loss: [0.9184599905014038]
2023-06-02 11:22:49.161 | INFO     | trainer:train_loop:183 - Epoch: [3/ 100] | Train loss: [0.7358736510276794]
2023-06-02 11:28:06.019 | INFO     | trainer:train_loop:183 - Epoch: [4/ 100] | Train loss: [0.6553568887710571]
2023-06-02 11:33:21.219 | INFO     | trainer:train_loop:183 - Epoch: [5/ 100] | Train loss: [0.6122416198253632]
2023-06-02 11:38:36.534 | INFO     | trainer:train_loop:183 - Epoch: [6/ 100] | Train loss: [0.7107514305114746]
2023-06-02 11:43:52.468 | INFO     | trainer:train_loop:183 - Epoch: [7/ 100] | Train loss: [0.5875168521404266]
2023-06-02 11:49:10.753 | INFO     | trainer:train_loop:183 - Epoch: [8/ 100] | Train loss: [0.552535654783249]
2023-06-02 11:54:30.546 | INFO     | trainer:train_loop:183 - Epoch: [9/ 100] | Train loss: [0.41839257991313933]
2023-06-02 11:59:46.982 | INFO     | trainer:train_loop:183 - Epoch: [10/ 100] | Train loss: [0.3590117803812027]
2023-06-02 12:05:03.970 | INFO     | trainer:train_loop:183 - Epoch: [11/ 100] | Train loss: [0.3102730973958969]
2023-06-02 12:10:22.736 | INFO     | trainer:train_loop:183 - Epoch: [12/ 100] | Train loss: [0.27400045055150984]
2023-06-02 12:15:43.278 | INFO     | trainer:train_loop:183 - Epoch: [13/ 100] | Train loss: [0.24953262603282927]
2023-06-02 12:21:02.309 | INFO     | trainer:train_loop:183 - Epoch: [14/ 100] | Train loss: [0.2414207181930542]
2023-06-02 12:26:19.561 | INFO     | trainer:train_loop:183 - Epoch: [15/ 100] | Train loss: [0.22336753383278846]
2023-06-02 12:31:36.855 | INFO     | trainer:train_loop:183 - Epoch: [16/ 100] | Train loss: [0.21086252525448798]
2023-06-02 12:36:53.991 | INFO     | trainer:train_loop:183 - Epoch: [17/ 100] | Train loss: [0.21622835662961007]
2023-06-02 12:42:12.833 | INFO     | trainer:train_loop:183 - Epoch: [18/ 100] | Train loss: [0.200346218675375]
2023-06-02 12:47:31.135 | INFO     | trainer:train_loop:183 - Epoch: [19/ 100] | Train loss: [0.18679116135835647]
2023-06-02 12:52:48.884 | INFO     | trainer:train_loop:183 - Epoch: [20/ 100] | Train loss: [0.18463101345300675]
2023-06-02 12:58:08.082 | INFO     | trainer:train_loop:183 - Epoch: [21/ 100] | Train loss: [0.1889553226530552]
2023-06-02 13:03:25.587 | INFO     | trainer:train_loop:183 - Epoch: [22/ 100] | Train loss: [0.18268806126713752]
2023-06-02 13:08:42.812 | INFO     | trainer:train_loop:183 - Epoch: [23/ 100] | Train loss: [0.17552169495821]
2023-06-02 13:14:02.394 | INFO     | trainer:train_loop:183 - Epoch: [24/ 100] | Train loss: [0.18685188090801239]
2023-06-02 13:19:20.604 | INFO     | trainer:train_loop:183 - Epoch: [25/ 100] | Train loss: [0.17356875056028367]
2023-06-02 13:24:40.308 | INFO     | trainer:train_loop:183 - Epoch: [26/ 100] | Train loss: [0.1636921371370554]
2023-06-02 13:29:58.770 | INFO     | trainer:train_loop:183 - Epoch: [27/ 100] | Train loss: [0.17609142562747002]
2023-06-02 13:35:16.032 | INFO     | trainer:train_loop:183 - Epoch: [28/ 100] | Train loss: [0.15924169689416887]
2023-06-02 13:40:33.480 | INFO     | trainer:train_loop:183 - Epoch: [29/ 100] | Train loss: [0.1639684723764658]
2023-06-02 13:45:52.301 | INFO     | trainer:train_loop:183 - Epoch: [30/ 100] | Train loss: [0.16333864426612854]
2023-06-02 13:51:11.626 | INFO     | trainer:train_loop:183 - Epoch: [31/ 100] | Train loss: [0.1729366236925125]
2023-06-02 13:56:30.172 | INFO     | trainer:train_loop:183 - Epoch: [32/ 100] | Train loss: [0.16325277864933013]
2023-06-02 14:01:49.574 | INFO     | trainer:train_loop:183 - Epoch: [33/ 100] | Train loss: [0.17455581298470496]
2023-06-02 14:07:10.515 | INFO     | trainer:train_loop:183 - Epoch: [34/ 100] | Train loss: [0.1369525075852871]
2023-06-02 14:12:29.241 | INFO     | trainer:train_loop:183 - Epoch: [35/ 100] | Train loss: [0.14785614615678788]
2023-06-02 14:17:49.854 | INFO     | trainer:train_loop:183 - Epoch: [36/ 100] | Train loss: [0.1394412629008293]
2023-06-02 14:23:09.188 | INFO     | trainer:train_loop:183 - Epoch: [37/ 100] | Train loss: [0.12240412411093712]
2023-06-02 14:28:29.867 | INFO     | trainer:train_loop:183 - Epoch: [38/ 100] | Train loss: [0.14696410268545151]
2023-06-02 14:33:49.450 | INFO     | trainer:train_loop:183 - Epoch: [39/ 100] | Train loss: [0.16063425400853157]
2023-06-02 14:39:12.720 | INFO     | trainer:train_loop:183 - Epoch: [40/ 100] | Train loss: [0.14420221185684204]
2023-06-02 14:44:30.105 | INFO     | trainer:train_loop:183 - Epoch: [41/ 100] | Train loss: [0.13516448214650154]
2023-06-02 14:49:50.326 | INFO     | trainer:train_loop:183 - Epoch: [42/ 100] | Train loss: [0.14429852038621901]
2023-06-02 14:55:10.877 | INFO     | trainer:train_loop:183 - Epoch: [43/ 100] | Train loss: [0.12417960780858993]
2023-06-02 15:00:30.163 | INFO     | trainer:train_loop:183 - Epoch: [44/ 100] | Train loss: [0.1286715368926525]
2023-06-02 15:05:49.310 | INFO     | trainer:train_loop:183 - Epoch: [45/ 100] | Train loss: [0.13877183443307878]
2023-06-02 15:11:09.414 | INFO     | trainer:train_loop:183 - Epoch: [46/ 100] | Train loss: [0.11719330281019211]
2023-06-02 15:16:29.325 | INFO     | trainer:train_loop:183 - Epoch: [47/ 100] | Train loss: [0.11784941697120667]
2023-06-02 15:21:48.060 | INFO     | trainer:train_loop:183 - Epoch: [48/ 100] | Train loss: [0.11082744202017784]
2023-06-02 15:27:07.386 | INFO     | trainer:train_loop:183 - Epoch: [49/ 100] | Train loss: [0.14264858137071132]
2023-06-02 15:32:27.528 | INFO     | trainer:train_loop:183 - Epoch: [50/ 100] | Train loss: [0.13244507206976414]
2023-06-02 15:37:50.930 | INFO     | trainer:train_loop:183 - Epoch: [51/ 100] | Train loss: [0.11198565474152565]
2023-06-02 15:43:11.653 | INFO     | trainer:train_loop:183 - Epoch: [52/ 100] | Train loss: [0.1040814917087555]
2023-06-02 15:48:30.737 | INFO     | trainer:train_loop:183 - Epoch: [53/ 100] | Train loss: [0.11045333583652973]
2023-06-02 15:53:50.020 | INFO     | trainer:train_loop:183 - Epoch: [54/ 100] | Train loss: [0.11397520712018012]
2023-06-02 15:59:10.633 | INFO     | trainer:train_loop:183 - Epoch: [55/ 100] | Train loss: [0.09570697598159313]
2023-06-02 16:04:28.632 | INFO     | trainer:train_loop:183 - Epoch: [56/ 100] | Train loss: [0.09001650531589984]
2023-06-02 16:09:48.170 | INFO     | trainer:train_loop:183 - Epoch: [57/ 100] | Train loss: [0.08525686430931091]
2023-06-02 16:15:07.027 | INFO     | trainer:train_loop:183 - Epoch: [58/ 100] | Train loss: [0.10067669275403023]
2023-06-02 16:20:25.545 | INFO     | trainer:train_loop:183 - Epoch: [59/ 100] | Train loss: [0.09892505645751953]
2023-06-02 16:25:45.469 | INFO     | trainer:train_loop:183 - Epoch: [60/ 100] | Train loss: [0.1008307667374611]
2023-06-02 16:31:06.335 | INFO     | trainer:train_loop:183 - Epoch: [61/ 100] | Train loss: [0.11207916890084743]
2023-06-02 16:36:25.177 | INFO     | trainer:train_loop:183 - Epoch: [62/ 100] | Train loss: [0.10553222212195397]
2023-06-02 16:41:47.737 | INFO     | trainer:train_loop:183 - Epoch: [63/ 100] | Train loss: [0.08543253819644452]
2023-06-02 16:47:10.417 | INFO     | trainer:train_loop:183 - Epoch: [64/ 100] | Train loss: [0.08576883052289486]
2023-06-02 16:52:29.172 | INFO     | trainer:train_loop:183 - Epoch: [65/ 100] | Train loss: [0.07804378201067448]
2023-06-02 16:57:48.853 | INFO     | trainer:train_loop:183 - Epoch: [66/ 100] | Train loss: [0.08860279221832752]
2023-06-02 17:03:09.064 | INFO     | trainer:train_loop:183 - Epoch: [67/ 100] | Train loss: [0.08065701898932456]
2023-06-02 17:08:28.739 | INFO     | trainer:train_loop:183 - Epoch: [68/ 100] | Train loss: [0.07599485991895198]
2023-06-02 17:13:47.006 | INFO     | trainer:train_loop:183 - Epoch: [69/ 100] | Train loss: [0.07585340100526809]
2023-06-02 17:19:05.054 | INFO     | trainer:train_loop:183 - Epoch: [70/ 100] | Train loss: [0.07002656300365925]
2023-06-02 17:24:26.506 | INFO     | trainer:train_loop:183 - Epoch: [71/ 100] | Train loss: [0.07803331027925015]
2023-06-02 17:29:44.704 | INFO     | trainer:train_loop:183 - Epoch: [72/ 100] | Train loss: [0.07460498559474946]
2023-06-02 17:35:04.008 | INFO     | trainer:train_loop:183 - Epoch: [73/ 100] | Train loss: [0.06355868463218212]
2023-06-02 17:40:22.955 | INFO     | trainer:train_loop:183 - Epoch: [74/ 100] | Train loss: [0.06839549611508847]
2023-06-02 17:45:40.251 | INFO     | trainer:train_loop:183 - Epoch: [75/ 100] | Train loss: [0.06532701687514782]
2023-06-02 17:51:00.246 | INFO     | trainer:train_loop:183 - Epoch: [76/ 100] | Train loss: [0.0709997736364603]
2023-06-02 17:56:18.137 | INFO     | trainer:train_loop:183 - Epoch: [77/ 100] | Train loss: [0.06502298240363598]
2023-06-02 18:01:36.985 | INFO     | trainer:train_loop:183 - Epoch: [78/ 100] | Train loss: [0.06334881488978862]
2023-06-02 18:06:54.160 | INFO     | trainer:train_loop:183 - Epoch: [79/ 100] | Train loss: [0.05860692799091339]
2023-06-02 18:12:13.052 | INFO     | trainer:train_loop:183 - Epoch: [80/ 100] | Train loss: [0.06323778277635575]
2023-06-02 18:17:33.074 | INFO     | trainer:train_loop:183 - Epoch: [81/ 100] | Train loss: [0.05874032194912433]
2023-06-02 18:22:52.499 | INFO     | trainer:train_loop:183 - Epoch: [82/ 100] | Train loss: [0.059867432817816736]
2023-06-02 18:28:10.254 | INFO     | trainer:train_loop:183 - Epoch: [83/ 100] | Train loss: [0.06492643420398235]
2023-06-02 18:33:27.844 | INFO     | trainer:train_loop:183 - Epoch: [84/ 100] | Train loss: [0.059282279342412945]
2023-06-02 18:38:46.902 | INFO     | trainer:train_loop:183 - Epoch: [85/ 100] | Train loss: [0.05889518444240093]
2023-06-02 18:44:06.253 | INFO     | trainer:train_loop:183 - Epoch: [86/ 100] | Train loss: [0.059689305767416954]
2023-06-02 18:49:25.508 | INFO     | trainer:train_loop:183 - Epoch: [87/ 100] | Train loss: [0.05512354497611523]
2023-06-02 18:54:44.306 | INFO     | trainer:train_loop:183 - Epoch: [88/ 100] | Train loss: [0.05355383311212063]
2023-06-02 19:00:02.615 | INFO     | trainer:train_loop:183 - Epoch: [89/ 100] | Train loss: [0.05660298359394073]
2023-06-02 19:05:22.134 | INFO     | trainer:train_loop:183 - Epoch: [90/ 100] | Train loss: [0.05563869485259056]
2023-06-02 19:10:39.348 | INFO     | trainer:train_loop:183 - Epoch: [91/ 100] | Train loss: [0.05602734760940075]
2023-06-02 19:15:58.066 | INFO     | trainer:train_loop:183 - Epoch: [92/ 100] | Train loss: [0.04950419615209103]
2023-06-02 19:21:17.137 | INFO     | trainer:train_loop:183 - Epoch: [93/ 100] | Train loss: [0.05474661925435066]
2023-06-02 19:26:37.517 | INFO     | trainer:train_loop:183 - Epoch: [94/ 100] | Train loss: [0.05403062506020069]
2023-06-02 19:31:57.073 | INFO     | trainer:train_loop:183 - Epoch: [95/ 100] | Train loss: [0.057414958983659746]
2023-06-02 19:37:15.336 | INFO     | trainer:train_loop:183 - Epoch: [96/ 100] | Train loss: [0.054042598202824595]
2023-06-02 19:42:35.380 | INFO     | trainer:train_loop:183 - Epoch: [97/ 100] | Train loss: [0.050215527698397634]
2023-06-02 19:47:55.256 | INFO     | trainer:train_loop:183 - Epoch: [98/ 100] | Train loss: [0.05207679833471775]
2023-06-02 19:53:13.674 | INFO     | trainer:train_loop:183 - Epoch: [99/ 100] | Train loss: [0.050900206536054614]
2023-06-02 19:58:31.678 | INFO     | trainer:train_loop:183 - Epoch: [100/ 100] | Train loss: [0.050097972333431245]
2023-06-02 19:58:32.201 | INFO     | trainer:train_loop:195 - [Saving Snapshot:]/root/neo_code_reco/configs/checkpoint/MiT-B3-FaPNHead_100.pth
2023-06-02 19:58:32.202 | INFO     | trainer:train_loop:204 - Training cost: 31895.227754205465seconds
