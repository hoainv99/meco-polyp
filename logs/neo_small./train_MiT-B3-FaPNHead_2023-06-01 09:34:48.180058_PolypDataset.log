2023-06-01 09:34:48.184 | INFO     | __main__:main:57 - Load config from configs/neo_small.yaml
2023-06-01 09:34:48.184 | INFO     | __main__:main:58 - {'dataset': {'data_path': '/root/neo_code/bkai-igh-neopolyp', 'train_data_path': ['/root/neo_code/bkai-igh-neopolyp'], 'test_data_path': ['/root/neo_code/bkai-igh-neopolyp'], 'val_data_path': ['/root/neo_code/bkai-igh-neopolyp']}, 'model': {'num_classes': 3, 'save_dir': '/root/neo_code_reco/configs/checkpoint', 'backbone': 'MiT-B3', 'head': 'FaPNHead', 'pretrained': 'mit_b3.pth'}, 'optimizer': {'name': 'adam', 'lr': 0.0001, 'clip': 0.5, 'scheduler': 'cosine_warmup', 'loss': 'multi_structure_loss'}, 'dev': 'cuda', 'train': {'start_from': 0, 'save_from': 99, 'num_epochs': 100, 'num_warmup_epoch': 8, 'is_val': False, 'size_rates': [0.75, 1, 1.25], 'dataloader': {'batchsize': 8, 'img_size': 384, 'shuffle': True, 'num_workers': 4, 'pin_memory': True, 'drop_last': True}, 'amp': False, 'ddp': False, 'augment': {'prob': 1, 'Flip_prob': 0.5, 'HueSaturationValue_prob': 0.5, 'RandomBrightnessContrast_prob': 0.5, 'crop_prob': 0.0, 'randomrotate90_prob': 0.5, 'ColorJitter_prob': 0.5}, 'augment_weak': {'prob': 1, 'Flip_prob': 0.5}}, 'val': {'dataloader': {'batchsize': 8, 'img_size': 384, 'shuffle': True, 'num_workers': 4, 'pin_memory': True, 'drop_last': False}}, 'test': {'dev': 'cuda', 'visualize': True, 'visualize_dir': '/home/s/hungpv/polyps/neo_visualize', 'vis_x': 180, 'vis_overwrite': False, 'checkpoint_dir': '/home/s/hungpv/polyps/checkpoint/neo/neo_small_v5/MiT-B3-FaPNHead_100.pth', 'dataloader': {'batchsize': 1, 'img_size': 384, 'shuffle': True, 'num_workers': 4, 'pin_memory': True, 'drop_last': False}, 'augment': {'prob': 1, 'Flip_prob': 0, 'HueSaturationValue_prob': 0, 'RandomBrightnessContrast_prob': 0, 'crop_prob': 0, 'randomrotate90_prob': 0, 'elastictransform_prob': 0, 'gridistortion_prob': 0, 'opticaldistortion_prob': 0, 'verticalflip_prob': 0, 'horizontalflip_prob': 0, 'randomgamma_prob': 0, 'CoarseDropout_prob': 0, 'RGBShift_prob': 0, 'MotionBlur_prob': 0, 'MedianBlur_prob': 0, 'GaussianBlur_prob': 0, 'GaussNoise_prob': 0, 'ChannelShuffle_prob': 0}}}
2023-06-01 09:34:48.185 | INFO     | __main__:main:59 - Getting datapath
2023-06-01 09:34:48.192 | INFO     | __main__:main:74 - There are 1000 images to train
2023-06-01 09:34:48.193 | INFO     | __main__:main:93 - Train model with no valid dataset
2023-06-01 09:34:48.193 | INFO     | __main__:main:95 - Loading data
2023-06-01 09:34:48.574 | INFO     | __main__:main:112 - 125 batches to train
2023-06-01 09:34:48.574 | INFO     | __main__:main:125 - Loading model
2023-06-01 09:34:48.574 | INFO     | __main__:main:146 - Loading checkpoint from mit_b3.pth ...
2023-06-01 09:34:54.008 | INFO     | __main__:main:190 - Training with FP32 ...
2023-06-01 09:40:04.712 | INFO     | trainer:train_loop:172 - Epoch: [1/ 100] | Train loss: [1.6015577826499938]
2023-06-01 09:45:15.478 | INFO     | trainer:train_loop:172 - Epoch: [2/ 100] | Train loss: [0.6530521032810211]
2023-06-01 09:50:26.469 | INFO     | trainer:train_loop:172 - Epoch: [3/ 100] | Train loss: [0.605714946269989]
2023-06-01 09:55:43.045 | INFO     | trainer:train_loop:172 - Epoch: [4/ 100] | Train loss: [0.43241714000701903]
2023-06-01 10:00:54.283 | INFO     | trainer:train_loop:172 - Epoch: [5/ 100] | Train loss: [0.352973924100399]
2023-06-01 10:06:05.830 | INFO     | trainer:train_loop:172 - Epoch: [6/ 100] | Train loss: [0.32735824859142304]
2023-06-01 10:11:17.011 | INFO     | trainer:train_loop:172 - Epoch: [7/ 100] | Train loss: [0.32070018696784974]
2023-06-01 10:16:31.650 | INFO     | trainer:train_loop:172 - Epoch: [8/ 100] | Train loss: [0.3272083293199539]
2023-06-01 10:21:47.849 | INFO     | trainer:train_loop:172 - Epoch: [9/ 100] | Train loss: [0.28183215057849886]
2023-06-01 10:27:02.171 | INFO     | trainer:train_loop:172 - Epoch: [10/ 100] | Train loss: [0.22349353808164596]
2023-06-01 10:32:18.377 | INFO     | trainer:train_loop:172 - Epoch: [11/ 100] | Train loss: [0.2221144750714302]
2023-06-01 10:37:33.999 | INFO     | trainer:train_loop:172 - Epoch: [12/ 100] | Train loss: [0.19321360233426094]
2023-06-01 10:42:50.476 | INFO     | trainer:train_loop:172 - Epoch: [13/ 100] | Train loss: [0.1681434576511383]
2023-06-01 10:48:08.038 | INFO     | trainer:train_loop:172 - Epoch: [14/ 100] | Train loss: [0.1634089798927307]
2023-06-01 10:53:24.051 | INFO     | trainer:train_loop:172 - Epoch: [15/ 100] | Train loss: [0.1562828492820263]
2023-06-01 10:58:39.975 | INFO     | trainer:train_loop:172 - Epoch: [16/ 100] | Train loss: [0.14567172452807425]
2023-06-01 11:03:55.879 | INFO     | trainer:train_loop:172 - Epoch: [17/ 100] | Train loss: [0.1518079663515091]
2023-06-01 11:09:12.418 | INFO     | trainer:train_loop:172 - Epoch: [18/ 100] | Train loss: [0.1339250259399414]
2023-06-01 11:14:28.120 | INFO     | trainer:train_loop:172 - Epoch: [19/ 100] | Train loss: [0.13821727472543716]
2023-06-01 11:19:44.589 | INFO     | trainer:train_loop:172 - Epoch: [20/ 100] | Train loss: [0.1363412355184555]
2023-06-01 11:25:01.739 | INFO     | trainer:train_loop:172 - Epoch: [21/ 100] | Train loss: [0.13160862454771996]
2023-06-01 11:30:13.074 | INFO     | trainer:train_loop:172 - Epoch: [22/ 100] | Train loss: [0.10547150084376335]
2023-06-01 11:35:26.106 | INFO     | trainer:train_loop:172 - Epoch: [23/ 100] | Train loss: [0.18153161615133284]
2023-06-01 11:40:39.356 | INFO     | trainer:train_loop:172 - Epoch: [24/ 100] | Train loss: [0.11964358112215996]
2023-06-01 11:45:53.302 | INFO     | trainer:train_loop:172 - Epoch: [25/ 100] | Train loss: [0.10701946622133254]
2023-06-01 11:51:08.451 | INFO     | trainer:train_loop:172 - Epoch: [26/ 100] | Train loss: [0.09966824665665626]
2023-06-01 11:56:23.320 | INFO     | trainer:train_loop:172 - Epoch: [27/ 100] | Train loss: [0.0864104837179184]
2023-06-01 12:01:37.624 | INFO     | trainer:train_loop:172 - Epoch: [28/ 100] | Train loss: [0.10016466683149337]
2023-06-01 12:06:53.582 | INFO     | trainer:train_loop:172 - Epoch: [29/ 100] | Train loss: [0.09172909367084503]
2023-06-01 12:12:08.698 | INFO     | trainer:train_loop:172 - Epoch: [30/ 100] | Train loss: [0.08376913797855377]
2023-06-01 12:17:24.067 | INFO     | trainer:train_loop:172 - Epoch: [31/ 100] | Train loss: [0.08641024923324585]
2023-06-01 12:22:40.775 | INFO     | trainer:train_loop:172 - Epoch: [32/ 100] | Train loss: [0.08662344086170197]
2023-06-01 12:27:56.889 | INFO     | trainer:train_loop:172 - Epoch: [33/ 100] | Train loss: [0.08215137085318565]
2023-06-01 12:33:13.658 | INFO     | trainer:train_loop:172 - Epoch: [34/ 100] | Train loss: [0.08440526184439659]
2023-06-01 12:38:28.727 | INFO     | trainer:train_loop:172 - Epoch: [35/ 100] | Train loss: [0.07740228033065796]
2023-06-01 12:43:43.677 | INFO     | trainer:train_loop:172 - Epoch: [36/ 100] | Train loss: [0.08194820177555084]
2023-06-01 12:48:58.085 | INFO     | trainer:train_loop:172 - Epoch: [37/ 100] | Train loss: [0.0817239508330822]
2023-06-01 12:54:13.083 | INFO     | trainer:train_loop:172 - Epoch: [38/ 100] | Train loss: [0.07602176460623741]
2023-06-01 12:59:30.242 | INFO     | trainer:train_loop:172 - Epoch: [39/ 100] | Train loss: [0.06767029719054699]
2023-06-01 13:04:46.344 | INFO     | trainer:train_loop:172 - Epoch: [40/ 100] | Train loss: [0.08199932563304901]
2023-06-01 13:10:02.296 | INFO     | trainer:train_loop:172 - Epoch: [41/ 100] | Train loss: [0.07073122552037239]
2023-06-01 13:15:18.832 | INFO     | trainer:train_loop:172 - Epoch: [42/ 100] | Train loss: [0.06722649866342545]
2023-06-01 13:20:34.877 | INFO     | trainer:train_loop:172 - Epoch: [43/ 100] | Train loss: [0.07240530014038087]
2023-06-01 13:25:52.462 | INFO     | trainer:train_loop:172 - Epoch: [44/ 100] | Train loss: [0.06469138953089713]
2023-06-01 13:31:08.803 | INFO     | trainer:train_loop:172 - Epoch: [45/ 100] | Train loss: [0.06911443135142327]
2023-06-01 13:36:25.523 | INFO     | trainer:train_loop:172 - Epoch: [46/ 100] | Train loss: [0.0681740966141224]
2023-06-01 13:41:42.401 | INFO     | trainer:train_loop:172 - Epoch: [47/ 100] | Train loss: [0.061147732451558114]
2023-06-01 13:46:58.099 | INFO     | trainer:train_loop:172 - Epoch: [48/ 100] | Train loss: [0.06076967489719391]
2023-06-01 13:52:16.866 | INFO     | trainer:train_loop:172 - Epoch: [49/ 100] | Train loss: [0.06378268736600876]
2023-06-01 13:57:33.902 | INFO     | trainer:train_loop:172 - Epoch: [50/ 100] | Train loss: [0.07163698925077915]
2023-06-01 14:02:52.566 | INFO     | trainer:train_loop:172 - Epoch: [51/ 100] | Train loss: [0.06920884853601456]
2023-06-01 14:08:09.940 | INFO     | trainer:train_loop:172 - Epoch: [52/ 100] | Train loss: [0.06089299368858338]
2023-06-01 14:13:28.057 | INFO     | trainer:train_loop:172 - Epoch: [53/ 100] | Train loss: [0.05559892205893993]
2023-06-01 14:18:45.642 | INFO     | trainer:train_loop:172 - Epoch: [54/ 100] | Train loss: [0.05845392595231533]
2023-06-01 14:24:03.402 | INFO     | trainer:train_loop:172 - Epoch: [55/ 100] | Train loss: [0.056961490482091905]
2023-06-01 14:29:21.341 | INFO     | trainer:train_loop:172 - Epoch: [56/ 100] | Train loss: [0.056206432908773425]
2023-06-01 14:34:38.613 | INFO     | trainer:train_loop:172 - Epoch: [57/ 100] | Train loss: [0.05663366051018238]
2023-06-01 14:39:55.413 | INFO     | trainer:train_loop:172 - Epoch: [58/ 100] | Train loss: [0.05802375489473343]
2023-06-01 14:45:12.806 | INFO     | trainer:train_loop:172 - Epoch: [59/ 100] | Train loss: [0.05902003228664398]
2023-06-01 14:50:30.270 | INFO     | trainer:train_loop:172 - Epoch: [60/ 100] | Train loss: [0.05245807103812695]
2023-06-01 14:55:46.532 | INFO     | trainer:train_loop:172 - Epoch: [61/ 100] | Train loss: [0.05556256948411465]
2023-06-01 15:01:05.822 | INFO     | trainer:train_loop:172 - Epoch: [62/ 100] | Train loss: [0.052668131813406946]
2023-06-01 15:06:23.223 | INFO     | trainer:train_loop:172 - Epoch: [63/ 100] | Train loss: [0.05175443637371063]
2023-06-01 15:11:40.334 | INFO     | trainer:train_loop:172 - Epoch: [64/ 100] | Train loss: [0.048525055691599844]
2023-06-01 15:16:57.567 | INFO     | trainer:train_loop:172 - Epoch: [65/ 100] | Train loss: [0.051206897512078284]
2023-06-01 15:22:14.812 | INFO     | trainer:train_loop:172 - Epoch: [66/ 100] | Train loss: [0.054547625690698626]
2023-06-01 15:27:31.394 | INFO     | trainer:train_loop:172 - Epoch: [67/ 100] | Train loss: [0.050510324493050575]
2023-06-01 15:32:49.537 | INFO     | trainer:train_loop:172 - Epoch: [68/ 100] | Train loss: [0.0497753484249115]
2023-06-01 15:38:06.737 | INFO     | trainer:train_loop:172 - Epoch: [69/ 100] | Train loss: [0.04897435055673122]
2023-06-01 15:43:23.140 | INFO     | trainer:train_loop:172 - Epoch: [70/ 100] | Train loss: [0.04984726957976818]
2023-06-01 15:48:40.185 | INFO     | trainer:train_loop:172 - Epoch: [71/ 100] | Train loss: [0.050221470817923546]
2023-06-01 15:53:56.296 | INFO     | trainer:train_loop:172 - Epoch: [72/ 100] | Train loss: [0.04822428691387177]
2023-06-01 15:59:13.822 | INFO     | trainer:train_loop:172 - Epoch: [73/ 100] | Train loss: [0.047154428616166116]
2023-06-01 16:04:30.323 | INFO     | trainer:train_loop:172 - Epoch: [74/ 100] | Train loss: [0.048596576496958734]
2023-06-01 16:09:48.072 | INFO     | trainer:train_loop:172 - Epoch: [75/ 100] | Train loss: [0.04882653968036175]
2023-06-01 16:15:04.910 | INFO     | trainer:train_loop:172 - Epoch: [76/ 100] | Train loss: [0.046748094737529756]
2023-06-01 16:20:23.555 | INFO     | trainer:train_loop:172 - Epoch: [77/ 100] | Train loss: [0.04704461832344532]
2023-06-01 16:25:41.516 | INFO     | trainer:train_loop:172 - Epoch: [78/ 100] | Train loss: [0.05023200006783009]
2023-06-01 16:30:58.699 | INFO     | trainer:train_loop:172 - Epoch: [79/ 100] | Train loss: [0.045959944054484364]
2023-06-01 16:36:16.442 | INFO     | trainer:train_loop:172 - Epoch: [80/ 100] | Train loss: [0.04566300390660763]
2023-06-01 16:41:32.276 | INFO     | trainer:train_loop:172 - Epoch: [81/ 100] | Train loss: [0.04479082454741001]
2023-06-01 16:46:49.857 | INFO     | trainer:train_loop:172 - Epoch: [82/ 100] | Train loss: [0.044707764610648154]
2023-06-01 16:52:05.261 | INFO     | trainer:train_loop:172 - Epoch: [83/ 100] | Train loss: [0.045126572787761686]
2023-06-01 16:57:21.255 | INFO     | trainer:train_loop:172 - Epoch: [84/ 100] | Train loss: [0.04531846657395363]
2023-06-01 17:02:37.373 | INFO     | trainer:train_loop:172 - Epoch: [85/ 100] | Train loss: [0.045173540651798245]
2023-06-01 17:07:52.998 | INFO     | trainer:train_loop:172 - Epoch: [86/ 100] | Train loss: [0.044459805205464366]
2023-06-01 17:13:09.741 | INFO     | trainer:train_loop:172 - Epoch: [87/ 100] | Train loss: [0.042695402711629866]
2023-06-01 17:18:28.793 | INFO     | trainer:train_loop:172 - Epoch: [88/ 100] | Train loss: [0.043541209548711775]
2023-06-01 17:23:46.007 | INFO     | trainer:train_loop:172 - Epoch: [89/ 100] | Train loss: [0.04102248167991638]
2023-06-01 17:29:02.767 | INFO     | trainer:train_loop:172 - Epoch: [90/ 100] | Train loss: [0.04257089765369892]
2023-06-01 17:34:18.874 | INFO     | trainer:train_loop:172 - Epoch: [91/ 100] | Train loss: [0.04142680981755257]
2023-06-01 17:39:36.278 | INFO     | trainer:train_loop:172 - Epoch: [92/ 100] | Train loss: [0.0413459954559803]
2023-06-01 17:44:54.209 | INFO     | trainer:train_loop:172 - Epoch: [93/ 100] | Train loss: [0.04257783088088036]
