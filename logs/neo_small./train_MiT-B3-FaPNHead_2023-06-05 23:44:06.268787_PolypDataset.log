2023-06-05 23:44:06.273 | INFO     | __main__:main:57 - Load config from configs/neo_small.yaml
2023-06-05 23:44:06.273 | INFO     | __main__:main:58 - {'dataset': {'data_path': '/root/neo_code_reco_mb/bkai-igh-neopolyp', 'train_data_path': ['/root/neo_code_reco_mb/bkai-igh-neopolyp'], 'test_data_path': ['/root/neo_code_reco_mb/bkai-igh-neopolyp/test/test'], 'val_data_path': ['/root/neo_code_reco_mb/bkai-igh-neopolyp']}, 'model': {'num_classes': 3, 'save_dir': '/root/neo_code_reco_mb/configs/checkpoint0606', 'backbone': 'MiT-B3', 'head': 'FaPNHead', 'pretrained': 'mit_b3.pth'}, 'optimizer': {'name': 'adam', 'lr': 0.0001, 'clip': 0.5, 'scheduler': 'cosine_warmup', 'loss': 'multi_structure_loss'}, 'dev': 'cuda', 'train': {'start_from': 0, 'save_from': 99, 'num_epochs': 100, 'num_warmup_epoch': 8, 'is_val': False, 'size_rates': [0.75, 1, 1.25], 'dataloader': {'batchsize': 8, 'img_size': 384, 'shuffle': True, 'num_workers': 4, 'pin_memory': True, 'drop_last': True}, 'amp': False, 'ddp': False, 'augment': {'prob': 1, 'Flip_prob': 0.5, 'HueSaturationValue_prob': 0.5, 'RandomBrightnessContrast_prob': 0.5, 'crop_prob': 0.0, 'randomrotate90_prob': 0.5, 'ColorJitter_prob': 0.5}, 'augment_weak': {'prob': 1, 'Flip_prob': 0.5}}, 'val': {'dataloader': {'batchsize': 8, 'img_size': 384, 'shuffle': True, 'num_workers': 4, 'pin_memory': True, 'drop_last': False}}, 'test': {'dev': 'cuda', 'visualize': True, 'visualize_dir': '/root/neo_code_reco_mb/neo_visualize', 'vis_x': 180, 'vis_overwrite': False, 'checkpoint_dir': '/root/neo_code_reco_mb/configs/checkpoint_0406/MiT-B3-FaPNHead_100_teacher.pth', 'dataloader': {'batchsize': 1, 'img_size': 384, 'shuffle': True, 'num_workers': 4, 'pin_memory': True, 'drop_last': False}, 'augment': {'prob': 1, 'Flip_prob': 0, 'HueSaturationValue_prob': 0, 'RandomBrightnessContrast_prob': 0, 'crop_prob': 0, 'randomrotate90_prob': 0, 'elastictransform_prob': 0, 'gridistortion_prob': 0, 'opticaldistortion_prob': 0, 'verticalflip_prob': 0, 'horizontalflip_prob': 0, 'randomgamma_prob': 0, 'CoarseDropout_prob': 0, 'RGBShift_prob': 0, 'MotionBlur_prob': 0, 'MedianBlur_prob': 0, 'GaussianBlur_prob': 0, 'GaussNoise_prob': 0, 'ChannelShuffle_prob': 0}}}
2023-06-05 23:44:06.273 | INFO     | __main__:main:59 - Getting datapath
2023-06-05 23:44:06.281 | INFO     | __main__:main:74 - There are 1000 images to train
2023-06-05 23:44:06.281 | INFO     | __main__:main:93 - Train model with no valid dataset
2023-06-05 23:44:06.282 | INFO     | __main__:main:95 - Loading data
2023-06-05 23:44:06.665 | INFO     | __main__:main:112 - 125 batches to train
2023-06-05 23:44:06.666 | INFO     | __main__:main:125 - Loading model
2023-06-05 23:44:06.666 | INFO     | __main__:main:146 - Loading checkpoint from mit_b3.pth ...
2023-06-05 23:44:12.471 | INFO     | __main__:main:190 - Training with FP32 ...
2023-06-05 23:49:35.265 | INFO     | trainer:train_loop:182 - Epoch: [1/ 100] | Train loss: [1.8656383032798767]
2023-06-05 23:54:56.654 | INFO     | trainer:train_loop:182 - Epoch: [2/ 100] | Train loss: [0.7943807449340821]
2023-06-06 00:00:18.828 | INFO     | trainer:train_loop:182 - Epoch: [3/ 100] | Train loss: [0.6943577671051026]
2023-06-06 00:05:39.703 | INFO     | trainer:train_loop:182 - Epoch: [4/ 100] | Train loss: [0.691353609085083]
2023-06-06 00:11:02.136 | INFO     | trainer:train_loop:182 - Epoch: [5/ 100] | Train loss: [0.6565872440338135]
2023-06-06 00:16:24.984 | INFO     | trainer:train_loop:182 - Epoch: [6/ 100] | Train loss: [0.644632504940033]
2023-06-06 00:21:51.374 | INFO     | trainer:train_loop:182 - Epoch: [7/ 100] | Train loss: [0.525253279209137]
2023-06-06 00:27:14.960 | INFO     | trainer:train_loop:182 - Epoch: [8/ 100] | Train loss: [0.4267870985269547]
2023-06-06 00:32:36.508 | INFO     | trainer:train_loop:182 - Epoch: [9/ 100] | Train loss: [0.3795242201089859]
2023-06-06 00:38:01.747 | INFO     | trainer:train_loop:182 - Epoch: [10/ 100] | Train loss: [0.3512645294070244]
2023-06-06 00:43:25.967 | INFO     | trainer:train_loop:182 - Epoch: [11/ 100] | Train loss: [0.3159155168533325]
2023-06-06 00:48:48.408 | INFO     | trainer:train_loop:182 - Epoch: [12/ 100] | Train loss: [0.31940893065929415]
2023-06-06 00:54:10.657 | INFO     | trainer:train_loop:182 - Epoch: [13/ 100] | Train loss: [0.2905332269668579]
2023-06-06 00:59:34.813 | INFO     | trainer:train_loop:182 - Epoch: [14/ 100] | Train loss: [0.275584403693676]
2023-06-06 01:04:57.528 | INFO     | trainer:train_loop:182 - Epoch: [15/ 100] | Train loss: [0.4094402972459793]
2023-06-06 01:10:22.647 | INFO     | trainer:train_loop:182 - Epoch: [16/ 100] | Train loss: [0.28834973931312563]
2023-06-06 01:15:45.772 | INFO     | trainer:train_loop:182 - Epoch: [17/ 100] | Train loss: [0.274722708016634]
2023-06-06 01:21:13.527 | INFO     | trainer:train_loop:182 - Epoch: [18/ 100] | Train loss: [0.25090001744031903]
2023-06-06 01:26:34.761 | INFO     | trainer:train_loop:182 - Epoch: [19/ 100] | Train loss: [0.252297039270401]
2023-06-06 01:32:01.442 | INFO     | trainer:train_loop:182 - Epoch: [20/ 100] | Train loss: [0.23968644204735756]
2023-06-06 01:37:26.081 | INFO     | trainer:train_loop:182 - Epoch: [21/ 100] | Train loss: [0.22507288807630538]
2023-06-06 01:42:51.176 | INFO     | trainer:train_loop:182 - Epoch: [22/ 100] | Train loss: [0.21986988660693169]
2023-06-06 01:48:16.126 | INFO     | trainer:train_loop:182 - Epoch: [23/ 100] | Train loss: [0.2148230853676796]
2023-06-06 01:53:41.245 | INFO     | trainer:train_loop:182 - Epoch: [24/ 100] | Train loss: [0.23373663794994354]
2023-06-06 01:59:07.350 | INFO     | trainer:train_loop:182 - Epoch: [25/ 100] | Train loss: [0.2111460440456867]
2023-06-06 02:04:32.824 | INFO     | trainer:train_loop:182 - Epoch: [26/ 100] | Train loss: [0.21929609814286233]
2023-06-06 02:10:00.171 | INFO     | trainer:train_loop:182 - Epoch: [27/ 100] | Train loss: [0.1903808002471924]
2023-06-06 02:15:26.549 | INFO     | trainer:train_loop:182 - Epoch: [28/ 100] | Train loss: [0.20010993027687074]
2023-06-06 02:20:53.292 | INFO     | trainer:train_loop:182 - Epoch: [29/ 100] | Train loss: [0.1957783281505108]
2023-06-06 02:26:20.516 | INFO     | trainer:train_loop:182 - Epoch: [30/ 100] | Train loss: [0.2035511820614338]
2023-06-06 02:31:48.718 | INFO     | trainer:train_loop:182 - Epoch: [31/ 100] | Train loss: [0.19162832735478877]
2023-06-06 02:37:13.923 | INFO     | trainer:train_loop:182 - Epoch: [32/ 100] | Train loss: [0.19763630419969558]
2023-06-06 02:42:39.783 | INFO     | trainer:train_loop:182 - Epoch: [33/ 100] | Train loss: [0.2181475519835949]
2023-06-06 02:48:03.035 | INFO     | trainer:train_loop:182 - Epoch: [34/ 100] | Train loss: [0.18910548877716066]
2023-06-06 02:53:27.145 | INFO     | trainer:train_loop:182 - Epoch: [35/ 100] | Train loss: [0.19371185141801833]
2023-06-06 02:58:54.162 | INFO     | trainer:train_loop:182 - Epoch: [36/ 100] | Train loss: [0.1662205947935581]
2023-06-06 03:04:18.818 | INFO     | trainer:train_loop:182 - Epoch: [37/ 100] | Train loss: [0.16057382798194886]
2023-06-06 03:09:44.753 | INFO     | trainer:train_loop:182 - Epoch: [38/ 100] | Train loss: [0.16787091600894927]
2023-06-06 03:15:09.952 | INFO     | trainer:train_loop:182 - Epoch: [39/ 100] | Train loss: [0.196873201161623]
2023-06-06 03:20:34.723 | INFO     | trainer:train_loop:182 - Epoch: [40/ 100] | Train loss: [0.1594866317808628]
2023-06-06 03:26:00.952 | INFO     | trainer:train_loop:182 - Epoch: [41/ 100] | Train loss: [0.18387625938653945]
2023-06-06 03:31:29.166 | INFO     | trainer:train_loop:182 - Epoch: [42/ 100] | Train loss: [0.16625247031450271]
2023-06-06 03:36:52.463 | INFO     | trainer:train_loop:182 - Epoch: [43/ 100] | Train loss: [0.14192911410331727]
2023-06-06 03:42:19.179 | INFO     | trainer:train_loop:182 - Epoch: [44/ 100] | Train loss: [0.14322332106530666]
2023-06-06 03:47:45.150 | INFO     | trainer:train_loop:182 - Epoch: [45/ 100] | Train loss: [0.14654895496368409]
2023-06-06 03:53:10.254 | INFO     | trainer:train_loop:182 - Epoch: [46/ 100] | Train loss: [0.16692197969555855]
2023-06-06 03:58:35.819 | INFO     | trainer:train_loop:182 - Epoch: [47/ 100] | Train loss: [0.13708251625299453]
2023-06-06 04:04:02.396 | INFO     | trainer:train_loop:182 - Epoch: [48/ 100] | Train loss: [0.13550902789831162]
2023-06-06 04:09:27.685 | INFO     | trainer:train_loop:182 - Epoch: [49/ 100] | Train loss: [0.1273572215139866]
2023-06-06 04:14:52.197 | INFO     | trainer:train_loop:182 - Epoch: [50/ 100] | Train loss: [0.13834665758907794]
2023-06-06 04:20:18.486 | INFO     | trainer:train_loop:182 - Epoch: [51/ 100] | Train loss: [0.12485123831033706]
2023-06-06 04:25:42.678 | INFO     | trainer:train_loop:182 - Epoch: [52/ 100] | Train loss: [0.17787049812078476]
2023-06-06 04:31:06.483 | INFO     | trainer:train_loop:182 - Epoch: [53/ 100] | Train loss: [0.13285844051837922]
2023-06-06 04:36:34.029 | INFO     | trainer:train_loop:182 - Epoch: [54/ 100] | Train loss: [0.13294229033589364]
2023-06-06 04:42:00.400 | INFO     | trainer:train_loop:182 - Epoch: [55/ 100] | Train loss: [0.13109030467271804]
2023-06-06 04:47:27.914 | INFO     | trainer:train_loop:182 - Epoch: [56/ 100] | Train loss: [0.1202737690359354]
2023-06-06 04:52:52.657 | INFO     | trainer:train_loop:182 - Epoch: [57/ 100] | Train loss: [0.1701992116868496]
2023-06-06 04:58:19.087 | INFO     | trainer:train_loop:182 - Epoch: [58/ 100] | Train loss: [0.11907385838031768]
2023-06-06 05:03:47.743 | INFO     | trainer:train_loop:182 - Epoch: [59/ 100] | Train loss: [0.1103784228116274]
2023-06-06 05:09:14.604 | INFO     | trainer:train_loop:182 - Epoch: [60/ 100] | Train loss: [0.11563796254992485]
2023-06-06 05:14:43.090 | INFO     | trainer:train_loop:182 - Epoch: [61/ 100] | Train loss: [0.10091801713407039]
2023-06-06 05:20:11.163 | INFO     | trainer:train_loop:182 - Epoch: [62/ 100] | Train loss: [0.1304973188638687]
2023-06-06 05:25:39.705 | INFO     | trainer:train_loop:182 - Epoch: [63/ 100] | Train loss: [0.10712834396958351]
2023-06-06 05:31:05.528 | INFO     | trainer:train_loop:182 - Epoch: [64/ 100] | Train loss: [0.09375725370645523]
2023-06-06 05:36:34.373 | INFO     | trainer:train_loop:182 - Epoch: [65/ 100] | Train loss: [0.09191943071782589]
2023-06-06 05:41:58.940 | INFO     | trainer:train_loop:182 - Epoch: [66/ 100] | Train loss: [0.09168524344265461]
2023-06-06 05:47:27.148 | INFO     | trainer:train_loop:182 - Epoch: [67/ 100] | Train loss: [0.08650187174975872]
2023-06-06 05:52:51.444 | INFO     | trainer:train_loop:182 - Epoch: [68/ 100] | Train loss: [0.09762217515707015]
2023-06-06 05:58:17.875 | INFO     | trainer:train_loop:182 - Epoch: [69/ 100] | Train loss: [0.0882245174497366]
2023-06-06 06:03:43.245 | INFO     | trainer:train_loop:182 - Epoch: [70/ 100] | Train loss: [0.08506368070840836]
2023-06-06 06:09:09.291 | INFO     | trainer:train_loop:182 - Epoch: [71/ 100] | Train loss: [0.07386811804771423]
2023-06-06 06:14:35.083 | INFO     | trainer:train_loop:182 - Epoch: [72/ 100] | Train loss: [0.08318931257724763]
2023-06-06 06:20:01.798 | INFO     | trainer:train_loop:182 - Epoch: [73/ 100] | Train loss: [0.07748044636845589]
2023-06-06 06:25:28.036 | INFO     | trainer:train_loop:182 - Epoch: [74/ 100] | Train loss: [0.07935866051912308]
2023-06-06 06:30:55.422 | INFO     | trainer:train_loop:182 - Epoch: [75/ 100] | Train loss: [0.0772085397541523]
2023-06-06 06:36:19.147 | INFO     | trainer:train_loop:182 - Epoch: [76/ 100] | Train loss: [0.08387222290039062]
2023-06-06 06:41:45.381 | INFO     | trainer:train_loop:182 - Epoch: [77/ 100] | Train loss: [0.08633273908495903]
2023-06-06 06:47:11.790 | INFO     | trainer:train_loop:182 - Epoch: [78/ 100] | Train loss: [0.07216001638770103]
2023-06-06 06:52:37.255 | INFO     | trainer:train_loop:182 - Epoch: [79/ 100] | Train loss: [0.07833422468602658]
2023-06-06 06:58:02.763 | INFO     | trainer:train_loop:182 - Epoch: [80/ 100] | Train loss: [0.07499211609363556]
2023-06-06 07:03:28.844 | INFO     | trainer:train_loop:182 - Epoch: [81/ 100] | Train loss: [0.06648035116493702]
2023-06-06 07:08:53.176 | INFO     | trainer:train_loop:182 - Epoch: [82/ 100] | Train loss: [0.07307920946180821]
2023-06-06 07:14:22.148 | INFO     | trainer:train_loop:182 - Epoch: [83/ 100] | Train loss: [0.06993814362585545]
2023-06-06 07:19:49.418 | INFO     | trainer:train_loop:182 - Epoch: [84/ 100] | Train loss: [0.06884737804532051]
2023-06-06 07:25:15.884 | INFO     | trainer:train_loop:182 - Epoch: [85/ 100] | Train loss: [0.066437993273139]
2023-06-06 07:30:43.144 | INFO     | trainer:train_loop:182 - Epoch: [86/ 100] | Train loss: [0.06214552396535873]
2023-06-06 07:36:11.859 | INFO     | trainer:train_loop:182 - Epoch: [87/ 100] | Train loss: [0.07547642770409584]
2023-06-06 07:41:37.877 | INFO     | trainer:train_loop:182 - Epoch: [88/ 100] | Train loss: [0.06971398235857487]
2023-06-06 07:47:03.340 | INFO     | trainer:train_loop:182 - Epoch: [89/ 100] | Train loss: [0.06762179762125015]
2023-06-06 07:52:27.400 | INFO     | trainer:train_loop:182 - Epoch: [90/ 100] | Train loss: [0.06120371522009373]
2023-06-06 07:57:54.748 | INFO     | trainer:train_loop:182 - Epoch: [91/ 100] | Train loss: [0.06390551248192787]
2023-06-06 08:03:20.730 | INFO     | trainer:train_loop:182 - Epoch: [92/ 100] | Train loss: [0.06764413356781006]
2023-06-06 08:08:48.475 | INFO     | trainer:train_loop:182 - Epoch: [93/ 100] | Train loss: [0.0641349633783102]
2023-06-06 08:14:15.355 | INFO     | trainer:train_loop:182 - Epoch: [94/ 100] | Train loss: [0.062583756133914]
2023-06-06 08:19:44.676 | INFO     | trainer:train_loop:182 - Epoch: [95/ 100] | Train loss: [0.05905837371945381]
2023-06-06 08:25:12.981 | INFO     | trainer:train_loop:182 - Epoch: [96/ 100] | Train loss: [0.06376728488504886]
2023-06-06 08:30:36.428 | INFO     | trainer:train_loop:182 - Epoch: [97/ 100] | Train loss: [0.06430400133132935]
2023-06-06 08:36:00.097 | INFO     | trainer:train_loop:182 - Epoch: [98/ 100] | Train loss: [0.05974431014060974]
2023-06-06 08:41:22.227 | INFO     | trainer:train_loop:182 - Epoch: [99/ 100] | Train loss: [0.05756287190318107]
2023-06-06 08:46:46.091 | INFO     | trainer:train_loop:182 - Epoch: [100/ 100] | Train loss: [0.06024179908633232]
2023-06-06 08:46:46.728 | INFO     | trainer:train_loop:203 - [Saving Snapshot:]/root/neo_code_reco_mb/configs/checkpoint0606/MiT-B3-FaPNHead_100.pth
2023-06-06 08:46:46.729 | INFO     | trainer:train_loop:212 - Training cost: 32552.789412193seconds
