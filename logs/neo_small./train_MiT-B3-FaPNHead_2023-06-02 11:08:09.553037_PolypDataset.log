2023-06-02 11:08:09.558 | INFO     | __main__:main:57 - Load config from configs/neo_small.yaml
2023-06-02 11:08:09.559 | INFO     | __main__:main:58 - {'dataset': {'data_path': '/root/neo_code_reco/bkai-igh-neopolyp', 'train_data_path': ['/root/neo_code_reco/bkai-igh-neopolyp'], 'test_data_path': ['/root/neo_code/bkai-igh-neopolyp/test/test'], 'val_data_path': ['/root/neo_code_reco/bkai-igh-neopolyp']}, 'model': {'num_classes': 3, 'save_dir': '/root/neo_code_reco/configs/checkpoint', 'backbone': 'MiT-B3', 'head': 'FaPNHead', 'pretrained': 'mit_b3.pth'}, 'optimizer': {'name': 'adam', 'lr': 0.0001, 'clip': 0.5, 'scheduler': 'cosine_warmup', 'loss': 'multi_structure_loss'}, 'dev': 'cuda', 'train': {'start_from': 0, 'save_from': 99, 'num_epochs': 100, 'num_warmup_epoch': 8, 'is_val': False, 'size_rates': [0.75, 1, 1.25], 'dataloader': {'batchsize': 8, 'img_size': 384, 'shuffle': True, 'num_workers': 4, 'pin_memory': True, 'drop_last': True}, 'amp': False, 'ddp': False, 'augment': {'prob': 1, 'Flip_prob': 0.5, 'HueSaturationValue_prob': 0.5, 'RandomBrightnessContrast_prob': 0.5, 'crop_prob': 0.0, 'randomrotate90_prob': 0.5, 'ColorJitter_prob': 0.5}, 'augment_weak': {'prob': 1, 'Flip_prob': 0.5}}, 'val': {'dataloader': {'batchsize': 8, 'img_size': 384, 'shuffle': True, 'num_workers': 4, 'pin_memory': True, 'drop_last': False}}, 'test': {'dev': 'cuda', 'visualize': True, 'visualize_dir': '/root/neo_code_reco/neo_visualize', 'vis_x': 180, 'vis_overwrite': False, 'checkpoint_dir': '/root/neo_code_reco/configs/checkpoint/MiT-B3-FaPNHead_100.pth', 'dataloader': {'batchsize': 1, 'img_size': 384, 'shuffle': True, 'num_workers': 4, 'pin_memory': True, 'drop_last': False}, 'augment': {'prob': 1, 'Flip_prob': 0, 'HueSaturationValue_prob': 0, 'RandomBrightnessContrast_prob': 0, 'crop_prob': 0, 'randomrotate90_prob': 0, 'elastictransform_prob': 0, 'gridistortion_prob': 0, 'opticaldistortion_prob': 0, 'verticalflip_prob': 0, 'horizontalflip_prob': 0, 'randomgamma_prob': 0, 'CoarseDropout_prob': 0, 'RGBShift_prob': 0, 'MotionBlur_prob': 0, 'MedianBlur_prob': 0, 'GaussianBlur_prob': 0, 'GaussNoise_prob': 0, 'ChannelShuffle_prob': 0}}}
2023-06-02 11:08:09.559 | INFO     | __main__:main:59 - Getting datapath
2023-06-02 11:08:09.568 | INFO     | __main__:main:74 - There are 1000 images to train
2023-06-02 11:08:09.568 | INFO     | __main__:main:93 - Train model with no valid dataset
2023-06-02 11:08:09.568 | INFO     | __main__:main:95 - Loading data
2023-06-02 11:08:10.022 | INFO     | __main__:main:112 - 125 batches to train
2023-06-02 11:08:10.023 | INFO     | __main__:main:125 - Loading model
2023-06-02 11:08:10.023 | INFO     | __main__:main:146 - Loading checkpoint from mit_b3.pth ...
2023-06-02 11:08:16.093 | INFO     | __main__:main:190 - Training with FP32 ...
2023-06-02 11:13:48.555 | INFO     | trainer:train_loop:183 - Epoch: [1/ 100] | Train loss: [5.658364577770233]
2023-06-02 11:19:16.546 | INFO     | trainer:train_loop:183 - Epoch: [2/ 100] | Train loss: [2.283696361541748]
2023-06-02 11:24:45.084 | INFO     | trainer:train_loop:183 - Epoch: [3/ 100] | Train loss: [1.9963690919876098]
2023-06-02 11:30:15.985 | INFO     | trainer:train_loop:183 - Epoch: [4/ 100] | Train loss: [1.8311227996349335]
2023-06-02 11:35:46.075 | INFO     | trainer:train_loop:183 - Epoch: [5/ 100] | Train loss: [1.679407638311386]
2023-06-02 11:41:16.198 | INFO     | trainer:train_loop:183 - Epoch: [6/ 100] | Train loss: [1.305426175713539]
2023-06-02 11:46:46.419 | INFO     | trainer:train_loop:183 - Epoch: [7/ 100] | Train loss: [1.0487563192844391]
2023-06-02 11:52:18.697 | INFO     | trainer:train_loop:183 - Epoch: [8/ 100] | Train loss: [0.977457889854908]
2023-06-02 11:57:52.154 | INFO     | trainer:train_loop:183 - Epoch: [9/ 100] | Train loss: [0.8956680253744126]
2023-06-02 12:03:24.455 | INFO     | trainer:train_loop:183 - Epoch: [10/ 100] | Train loss: [0.7440502219498157]
2023-06-02 12:08:55.485 | INFO     | trainer:train_loop:183 - Epoch: [11/ 100] | Train loss: [0.6830450714528561]
2023-06-02 12:14:26.719 | INFO     | trainer:train_loop:183 - Epoch: [12/ 100] | Train loss: [0.585270412415266]
2023-06-02 12:20:00.289 | INFO     | trainer:train_loop:183 - Epoch: [13/ 100] | Train loss: [0.5907492505908012]
2023-06-02 12:25:36.407 | INFO     | trainer:train_loop:183 - Epoch: [14/ 100] | Train loss: [0.5610168439149856]
2023-06-02 12:31:07.017 | INFO     | trainer:train_loop:183 - Epoch: [15/ 100] | Train loss: [0.528977295577526]
2023-06-02 12:36:38.729 | INFO     | trainer:train_loop:183 - Epoch: [16/ 100] | Train loss: [0.6143584817647934]
2023-06-02 12:42:10.834 | INFO     | trainer:train_loop:183 - Epoch: [17/ 100] | Train loss: [0.5001096016168595]
2023-06-02 12:47:44.789 | INFO     | trainer:train_loop:183 - Epoch: [18/ 100] | Train loss: [0.4811041660308838]
2023-06-02 12:53:16.430 | INFO     | trainer:train_loop:183 - Epoch: [19/ 100] | Train loss: [0.42849780175089835]
2023-06-02 12:58:48.700 | INFO     | trainer:train_loop:183 - Epoch: [20/ 100] | Train loss: [0.4199389932453632]
2023-06-02 13:04:21.731 | INFO     | trainer:train_loop:183 - Epoch: [21/ 100] | Train loss: [0.4321208602786064]
2023-06-02 13:09:54.401 | INFO     | trainer:train_loop:183 - Epoch: [22/ 100] | Train loss: [0.37661732321977615]
2023-06-02 13:15:27.476 | INFO     | trainer:train_loop:183 - Epoch: [23/ 100] | Train loss: [0.3913081517219543]
2023-06-02 13:21:01.981 | INFO     | trainer:train_loop:183 - Epoch: [24/ 100] | Train loss: [0.3661703192293644]
2023-06-02 13:26:35.471 | INFO     | trainer:train_loop:183 - Epoch: [25/ 100] | Train loss: [0.3611643953025341]
2023-06-02 13:32:07.445 | INFO     | trainer:train_loop:183 - Epoch: [26/ 100] | Train loss: [0.353664081633091]
2023-06-02 13:37:40.864 | INFO     | trainer:train_loop:183 - Epoch: [27/ 100] | Train loss: [0.3333656752705574]
2023-06-02 13:43:15.126 | INFO     | trainer:train_loop:183 - Epoch: [28/ 100] | Train loss: [0.31515676239132884]
2023-06-02 13:48:47.779 | INFO     | trainer:train_loop:183 - Epoch: [29/ 100] | Train loss: [0.29427648785710336]
2023-06-02 13:54:20.533 | INFO     | trainer:train_loop:183 - Epoch: [30/ 100] | Train loss: [0.3456596215069294]
2023-06-02 13:59:55.005 | INFO     | trainer:train_loop:183 - Epoch: [31/ 100] | Train loss: [0.28600638711452486]
2023-06-02 14:05:27.454 | INFO     | trainer:train_loop:183 - Epoch: [32/ 100] | Train loss: [0.28291164815425873]
2023-06-02 14:11:02.415 | INFO     | trainer:train_loop:183 - Epoch: [33/ 100] | Train loss: [0.26757154205441475]
2023-06-02 14:16:33.643 | INFO     | trainer:train_loop:183 - Epoch: [34/ 100] | Train loss: [0.3590752440392971]
2023-06-02 14:22:05.779 | INFO     | trainer:train_loop:183 - Epoch: [35/ 100] | Train loss: [0.592019443422556]
2023-06-02 14:27:37.536 | INFO     | trainer:train_loop:183 - Epoch: [36/ 100] | Train loss: [0.373760866522789]
2023-06-02 14:33:09.921 | INFO     | trainer:train_loop:183 - Epoch: [37/ 100] | Train loss: [0.29007390731573107]
2023-06-02 14:38:44.811 | INFO     | trainer:train_loop:183 - Epoch: [38/ 100] | Train loss: [0.26373462021350863]
2023-06-02 14:44:18.301 | INFO     | trainer:train_loop:183 - Epoch: [39/ 100] | Train loss: [0.2613461730778217]
2023-06-02 14:49:51.462 | INFO     | trainer:train_loop:183 - Epoch: [40/ 100] | Train loss: [0.23396317449212073]
2023-06-02 14:55:24.072 | INFO     | trainer:train_loop:183 - Epoch: [41/ 100] | Train loss: [0.22348962435126304]
2023-06-02 15:01:00.721 | INFO     | trainer:train_loop:183 - Epoch: [42/ 100] | Train loss: [0.21782553887367248]
2023-06-02 15:06:31.936 | INFO     | trainer:train_loop:183 - Epoch: [43/ 100] | Train loss: [0.2311703390479088]
2023-06-02 15:12:02.052 | INFO     | trainer:train_loop:183 - Epoch: [44/ 100] | Train loss: [0.22639741607010364]
2023-06-02 15:17:33.413 | INFO     | trainer:train_loop:183 - Epoch: [45/ 100] | Train loss: [0.20941250489652158]
2023-06-02 15:23:03.571 | INFO     | trainer:train_loop:183 - Epoch: [46/ 100] | Train loss: [0.22547188882529737]
2023-06-02 15:28:35.623 | INFO     | trainer:train_loop:183 - Epoch: [47/ 100] | Train loss: [0.2245044737458229]
2023-06-02 15:34:08.057 | INFO     | trainer:train_loop:183 - Epoch: [48/ 100] | Train loss: [0.1924137408733368]
2023-06-02 15:39:37.457 | INFO     | trainer:train_loop:183 - Epoch: [49/ 100] | Train loss: [0.20526322232186794]
2023-06-02 15:45:08.517 | INFO     | trainer:train_loop:183 - Epoch: [50/ 100] | Train loss: [0.20219568651914596]
2023-06-02 15:50:41.560 | INFO     | trainer:train_loop:183 - Epoch: [51/ 100] | Train loss: [0.20672027285397052]
2023-06-02 15:56:16.674 | INFO     | trainer:train_loop:183 - Epoch: [52/ 100] | Train loss: [0.19289144536852837]
2023-06-02 16:01:49.872 | INFO     | trainer:train_loop:183 - Epoch: [53/ 100] | Train loss: [0.21272974283993243]
2023-06-02 16:07:20.417 | INFO     | trainer:train_loop:183 - Epoch: [54/ 100] | Train loss: [0.18407685782015323]
2023-06-02 16:12:54.695 | INFO     | trainer:train_loop:183 - Epoch: [55/ 100] | Train loss: [0.1950322202593088]
2023-06-02 16:18:28.805 | INFO     | trainer:train_loop:183 - Epoch: [56/ 100] | Train loss: [0.20196811838448048]
2023-06-02 16:24:02.735 | INFO     | trainer:train_loop:183 - Epoch: [57/ 100] | Train loss: [0.20634509813785554]
2023-06-02 16:29:36.735 | INFO     | trainer:train_loop:183 - Epoch: [58/ 100] | Train loss: [0.18525665262341498]
2023-06-02 16:35:11.439 | INFO     | trainer:train_loop:183 - Epoch: [59/ 100] | Train loss: [0.18780310596525668]
