2023-06-01 18:00:25.276 | INFO     | __main__:main:57 - Load config from configs/neo_small.yaml
2023-06-01 18:00:25.276 | INFO     | __main__:main:58 - {'dataset': {'data_path': '/root/neo_code/bkai-igh-neopolyp', 'train_data_path': ['/root/neo_code/bkai-igh-neopolyp'], 'test_data_path': ['/root/neo_code/bkai-igh-neopolyp'], 'val_data_path': ['/root/neo_code/bkai-igh-neopolyp']}, 'model': {'num_classes': 3, 'save_dir': '/root/neo_code_reco/configs/checkpoint', 'backbone': 'MiT-B3', 'head': 'FaPNHead', 'pretrained': 'mit_b3.pth'}, 'optimizer': {'name': 'adam', 'lr': 0.0001, 'clip': 0.5, 'scheduler': 'cosine_warmup', 'loss': 'multi_structure_loss'}, 'dev': 'cuda', 'train': {'start_from': 0, 'save_from': 99, 'num_epochs': 100, 'num_warmup_epoch': 8, 'is_val': False, 'size_rates': [0.75, 1, 1.25], 'dataloader': {'batchsize': 8, 'img_size': 384, 'shuffle': True, 'num_workers': 4, 'pin_memory': True, 'drop_last': True}, 'amp': False, 'ddp': False, 'augment': {'prob': 1, 'Flip_prob': 0.5, 'HueSaturationValue_prob': 0.5, 'RandomBrightnessContrast_prob': 0.5, 'crop_prob': 0.0, 'randomrotate90_prob': 0.5, 'ColorJitter_prob': 0.5}, 'augment_weak': {'prob': 1, 'Flip_prob': 0.5}}, 'val': {'dataloader': {'batchsize': 8, 'img_size': 384, 'shuffle': True, 'num_workers': 4, 'pin_memory': True, 'drop_last': False}}, 'test': {'dev': 'cuda', 'visualize': True, 'visualize_dir': '/home/s/hungpv/polyps/neo_visualize', 'vis_x': 180, 'vis_overwrite': False, 'checkpoint_dir': '/home/s/hungpv/polyps/checkpoint/neo/neo_small_v5/MiT-B3-FaPNHead_100.pth', 'dataloader': {'batchsize': 1, 'img_size': 384, 'shuffle': True, 'num_workers': 4, 'pin_memory': True, 'drop_last': False}, 'augment': {'prob': 1, 'Flip_prob': 0, 'HueSaturationValue_prob': 0, 'RandomBrightnessContrast_prob': 0, 'crop_prob': 0, 'randomrotate90_prob': 0, 'elastictransform_prob': 0, 'gridistortion_prob': 0, 'opticaldistortion_prob': 0, 'verticalflip_prob': 0, 'horizontalflip_prob': 0, 'randomgamma_prob': 0, 'CoarseDropout_prob': 0, 'RGBShift_prob': 0, 'MotionBlur_prob': 0, 'MedianBlur_prob': 0, 'GaussianBlur_prob': 0, 'GaussNoise_prob': 0, 'ChannelShuffle_prob': 0}}}
2023-06-01 18:00:25.276 | INFO     | __main__:main:59 - Getting datapath
2023-06-01 18:00:25.285 | INFO     | __main__:main:74 - There are 1000 images to train
2023-06-01 18:00:25.285 | INFO     | __main__:main:93 - Train model with no valid dataset
2023-06-01 18:00:25.285 | INFO     | __main__:main:95 - Loading data
2023-06-01 18:00:25.660 | INFO     | __main__:main:112 - 125 batches to train
2023-06-01 18:00:25.661 | INFO     | __main__:main:125 - Loading model
2023-06-01 18:00:25.661 | INFO     | __main__:main:146 - Loading checkpoint from mit_b3.pth ...
2023-06-01 18:00:31.352 | INFO     | __main__:main:190 - Training with FP32 ...
2023-06-01 18:05:35.152 | INFO     | trainer:train_loop:171 - Epoch: [1/ 100] | Train loss: [1.6966801853179931]
2023-06-01 18:10:43.384 | INFO     | trainer:train_loop:171 - Epoch: [2/ 100] | Train loss: [0.7512400307655335]
2023-06-01 18:15:54.364 | INFO     | trainer:train_loop:171 - Epoch: [3/ 100] | Train loss: [0.670824462890625]
2023-06-01 18:21:06.908 | INFO     | trainer:train_loop:171 - Epoch: [4/ 100] | Train loss: [0.5240538425445557]
2023-06-01 18:26:20.172 | INFO     | trainer:train_loop:171 - Epoch: [5/ 100] | Train loss: [0.3955038186311722]
2023-06-01 18:31:32.381 | INFO     | trainer:train_loop:171 - Epoch: [6/ 100] | Train loss: [0.356839093208313]
2023-06-01 18:36:44.736 | INFO     | trainer:train_loop:171 - Epoch: [7/ 100] | Train loss: [0.34581498968601226]
2023-06-01 18:41:57.594 | INFO     | trainer:train_loop:171 - Epoch: [8/ 100] | Train loss: [0.3074850252866745]
2023-06-01 18:47:11.309 | INFO     | trainer:train_loop:171 - Epoch: [9/ 100] | Train loss: [0.27233933192491533]
2023-06-01 18:52:23.125 | INFO     | trainer:train_loop:171 - Epoch: [10/ 100] | Train loss: [0.24256253749132156]
2023-06-01 18:57:35.643 | INFO     | trainer:train_loop:171 - Epoch: [11/ 100] | Train loss: [0.20080882093310357]
2023-06-01 19:02:46.727 | INFO     | trainer:train_loop:171 - Epoch: [12/ 100] | Train loss: [0.191124456346035]
2023-06-01 19:07:59.861 | INFO     | trainer:train_loop:171 - Epoch: [13/ 100] | Train loss: [0.18360370108485222]
2023-06-01 19:13:12.772 | INFO     | trainer:train_loop:171 - Epoch: [14/ 100] | Train loss: [0.18357569631934165]
2023-06-01 19:18:25.046 | INFO     | trainer:train_loop:171 - Epoch: [15/ 100] | Train loss: [0.19754076969623566]
2023-06-01 19:23:36.252 | INFO     | trainer:train_loop:171 - Epoch: [16/ 100] | Train loss: [0.15790803614258767]
2023-06-01 19:28:47.030 | INFO     | trainer:train_loop:171 - Epoch: [17/ 100] | Train loss: [0.1456832775771618]
2023-06-01 19:33:58.063 | INFO     | trainer:train_loop:171 - Epoch: [18/ 100] | Train loss: [0.14799263912439348]
2023-06-01 19:39:09.831 | INFO     | trainer:train_loop:171 - Epoch: [19/ 100] | Train loss: [0.14127147176861762]
2023-06-01 19:44:22.103 | INFO     | trainer:train_loop:171 - Epoch: [20/ 100] | Train loss: [0.13331801232695578]
2023-06-01 19:49:34.857 | INFO     | trainer:train_loop:171 - Epoch: [21/ 100] | Train loss: [0.12975038677453996]
2023-06-01 19:54:47.028 | INFO     | trainer:train_loop:171 - Epoch: [22/ 100] | Train loss: [0.1238104233443737]
2023-06-01 19:59:58.270 | INFO     | trainer:train_loop:171 - Epoch: [23/ 100] | Train loss: [0.10656181252002717]
2023-06-01 20:05:10.387 | INFO     | trainer:train_loop:171 - Epoch: [24/ 100] | Train loss: [0.10912789607048035]
2023-06-01 20:10:21.541 | INFO     | trainer:train_loop:171 - Epoch: [25/ 100] | Train loss: [0.11152646917104721]
2023-06-01 20:15:34.462 | INFO     | trainer:train_loop:171 - Epoch: [26/ 100] | Train loss: [0.1148663929104805]
2023-06-01 20:20:46.237 | INFO     | trainer:train_loop:171 - Epoch: [27/ 100] | Train loss: [0.0886924121081829]
2023-06-01 20:25:59.662 | INFO     | trainer:train_loop:171 - Epoch: [28/ 100] | Train loss: [0.09509225183725357]
2023-06-01 20:31:10.821 | INFO     | trainer:train_loop:171 - Epoch: [29/ 100] | Train loss: [0.0892923742234707]
2023-06-01 20:36:22.966 | INFO     | trainer:train_loop:171 - Epoch: [30/ 100] | Train loss: [0.08787316742539406]
2023-06-01 20:41:34.551 | INFO     | trainer:train_loop:171 - Epoch: [31/ 100] | Train loss: [0.08450784462690353]
2023-06-01 20:46:46.452 | INFO     | trainer:train_loop:171 - Epoch: [32/ 100] | Train loss: [0.08949841159582138]
2023-06-01 20:51:58.498 | INFO     | trainer:train_loop:171 - Epoch: [33/ 100] | Train loss: [0.08672057035565377]
2023-06-01 20:57:12.905 | INFO     | trainer:train_loop:171 - Epoch: [34/ 100] | Train loss: [0.09513592359423638]
2023-06-01 21:02:25.824 | INFO     | trainer:train_loop:171 - Epoch: [35/ 100] | Train loss: [0.08213638240098953]
2023-06-01 21:07:37.862 | INFO     | trainer:train_loop:171 - Epoch: [36/ 100] | Train loss: [0.08318059954047204]
2023-06-01 21:12:47.889 | INFO     | trainer:train_loop:171 - Epoch: [37/ 100] | Train loss: [0.07490544706583023]
2023-06-01 21:17:59.270 | INFO     | trainer:train_loop:171 - Epoch: [38/ 100] | Train loss: [0.07262193071842193]
2023-06-01 21:23:11.085 | INFO     | trainer:train_loop:171 - Epoch: [39/ 100] | Train loss: [0.07192229060828685]
2023-06-01 21:28:21.586 | INFO     | trainer:train_loop:171 - Epoch: [40/ 100] | Train loss: [0.07929245534539223]
2023-06-01 21:33:33.928 | INFO     | trainer:train_loop:171 - Epoch: [41/ 100] | Train loss: [0.07061185812950134]
2023-06-01 21:38:46.044 | INFO     | trainer:train_loop:171 - Epoch: [42/ 100] | Train loss: [0.06983899959921837]
2023-06-01 21:43:58.640 | INFO     | trainer:train_loop:171 - Epoch: [43/ 100] | Train loss: [0.06615555506944656]
2023-06-01 21:49:11.687 | INFO     | trainer:train_loop:171 - Epoch: [44/ 100] | Train loss: [0.06493222369253636]
2023-06-01 21:54:23.256 | INFO     | trainer:train_loop:171 - Epoch: [45/ 100] | Train loss: [0.07017543765902519]
2023-06-01 21:59:35.838 | INFO     | trainer:train_loop:171 - Epoch: [46/ 100] | Train loss: [0.06432407301664353]
2023-06-01 22:04:47.124 | INFO     | trainer:train_loop:171 - Epoch: [47/ 100] | Train loss: [0.061104850947856906]
2023-06-01 22:09:58.578 | INFO     | trainer:train_loop:171 - Epoch: [48/ 100] | Train loss: [0.05739241436123848]
2023-06-01 22:15:10.604 | INFO     | trainer:train_loop:171 - Epoch: [49/ 100] | Train loss: [0.056934996724128724]
2023-06-01 22:20:23.719 | INFO     | trainer:train_loop:171 - Epoch: [50/ 100] | Train loss: [0.05619480964541435]
2023-06-01 22:25:37.236 | INFO     | trainer:train_loop:171 - Epoch: [51/ 100] | Train loss: [0.05791940021514892]
2023-06-01 22:30:50.875 | INFO     | trainer:train_loop:171 - Epoch: [52/ 100] | Train loss: [0.060846654057502746]
2023-06-01 22:36:01.654 | INFO     | trainer:train_loop:171 - Epoch: [53/ 100] | Train loss: [0.05468800427019596]
2023-06-01 22:41:14.907 | INFO     | trainer:train_loop:171 - Epoch: [54/ 100] | Train loss: [0.056565464437007905]
2023-06-01 22:46:27.122 | INFO     | trainer:train_loop:171 - Epoch: [55/ 100] | Train loss: [0.05479649509489536]
2023-06-01 22:51:40.488 | INFO     | trainer:train_loop:171 - Epoch: [56/ 100] | Train loss: [0.05536197426915169]
2023-06-01 22:56:54.446 | INFO     | trainer:train_loop:171 - Epoch: [57/ 100] | Train loss: [0.052134600579738614]
2023-06-01 23:02:07.886 | INFO     | trainer:train_loop:171 - Epoch: [58/ 100] | Train loss: [0.0493631292283535]
2023-06-01 23:07:19.180 | INFO     | trainer:train_loop:171 - Epoch: [59/ 100] | Train loss: [0.050818682596087454]
2023-06-01 23:12:32.775 | INFO     | trainer:train_loop:171 - Epoch: [60/ 100] | Train loss: [0.052802629500627515]
2023-06-01 23:17:45.284 | INFO     | trainer:train_loop:171 - Epoch: [61/ 100] | Train loss: [0.04882743842899799]
2023-06-01 23:22:56.755 | INFO     | trainer:train_loop:171 - Epoch: [62/ 100] | Train loss: [0.04964492237567902]
2023-06-01 23:28:11.159 | INFO     | trainer:train_loop:171 - Epoch: [63/ 100] | Train loss: [0.050071802020072935]
2023-06-01 23:33:23.208 | INFO     | trainer:train_loop:171 - Epoch: [64/ 100] | Train loss: [0.05051593743264675]
2023-06-01 23:38:36.184 | INFO     | trainer:train_loop:171 - Epoch: [65/ 100] | Train loss: [0.0559319753497839]
2023-06-01 23:43:49.175 | INFO     | trainer:train_loop:171 - Epoch: [66/ 100] | Train loss: [0.048949403747916224]
2023-06-01 23:49:00.656 | INFO     | trainer:train_loop:171 - Epoch: [67/ 100] | Train loss: [0.048612383142113684]
2023-06-01 23:54:12.339 | INFO     | trainer:train_loop:171 - Epoch: [68/ 100] | Train loss: [0.04789364168047905]
2023-06-01 23:59:23.609 | INFO     | trainer:train_loop:171 - Epoch: [69/ 100] | Train loss: [0.05066708843410015]
2023-06-02 00:04:35.848 | INFO     | trainer:train_loop:171 - Epoch: [70/ 100] | Train loss: [0.045665059104561805]
2023-06-02 00:09:47.196 | INFO     | trainer:train_loop:171 - Epoch: [71/ 100] | Train loss: [0.04596529327332974]
2023-06-02 00:14:58.698 | INFO     | trainer:train_loop:171 - Epoch: [72/ 100] | Train loss: [0.045660308092832565]
2023-06-02 00:20:10.218 | INFO     | trainer:train_loop:171 - Epoch: [73/ 100] | Train loss: [0.045096043765544894]
2023-06-02 00:25:23.372 | INFO     | trainer:train_loop:171 - Epoch: [74/ 100] | Train loss: [0.045401350989937785]
2023-06-02 00:30:36.295 | INFO     | trainer:train_loop:171 - Epoch: [75/ 100] | Train loss: [0.043603646740317345]
2023-06-02 00:35:48.639 | INFO     | trainer:train_loop:171 - Epoch: [76/ 100] | Train loss: [0.044316360101103784]
2023-06-02 00:41:00.315 | INFO     | trainer:train_loop:171 - Epoch: [77/ 100] | Train loss: [0.04335257367789745]
2023-06-02 00:46:13.695 | INFO     | trainer:train_loop:171 - Epoch: [78/ 100] | Train loss: [0.04428393755853176]
2023-06-02 00:51:25.461 | INFO     | trainer:train_loop:171 - Epoch: [79/ 100] | Train loss: [0.04385946011543274]
2023-06-02 00:56:38.312 | INFO     | trainer:train_loop:171 - Epoch: [80/ 100] | Train loss: [0.043874971106648446]
2023-06-02 01:01:50.545 | INFO     | trainer:train_loop:171 - Epoch: [81/ 100] | Train loss: [0.04253345455229282]
2023-06-02 01:07:03.349 | INFO     | trainer:train_loop:171 - Epoch: [82/ 100] | Train loss: [0.043649791225790976]
2023-06-02 01:12:15.097 | INFO     | trainer:train_loop:171 - Epoch: [83/ 100] | Train loss: [0.041735811606049535]
2023-06-02 01:17:26.287 | INFO     | trainer:train_loop:171 - Epoch: [84/ 100] | Train loss: [0.043194940134882925]
2023-06-02 01:22:39.167 | INFO     | trainer:train_loop:171 - Epoch: [85/ 100] | Train loss: [0.04154974147677422]
2023-06-02 01:27:53.167 | INFO     | trainer:train_loop:171 - Epoch: [86/ 100] | Train loss: [0.042285545542836186]
2023-06-02 01:33:05.814 | INFO     | trainer:train_loop:171 - Epoch: [87/ 100] | Train loss: [0.04247290071845054]
2023-06-02 01:38:17.348 | INFO     | trainer:train_loop:171 - Epoch: [88/ 100] | Train loss: [0.04132377943396568]
2023-06-02 01:43:29.097 | INFO     | trainer:train_loop:171 - Epoch: [89/ 100] | Train loss: [0.04085345131158829]
2023-06-02 01:48:40.707 | INFO     | trainer:train_loop:171 - Epoch: [90/ 100] | Train loss: [0.04177779728174209]
2023-06-02 01:53:53.616 | INFO     | trainer:train_loop:171 - Epoch: [91/ 100] | Train loss: [0.03988821513950825]
2023-06-02 01:59:05.580 | INFO     | trainer:train_loop:171 - Epoch: [92/ 100] | Train loss: [0.041361929520964624]
2023-06-02 02:04:18.379 | INFO     | trainer:train_loop:171 - Epoch: [93/ 100] | Train loss: [0.04200907474756241]
2023-06-02 02:09:32.221 | INFO     | trainer:train_loop:171 - Epoch: [94/ 100] | Train loss: [0.040808149293065074]
2023-06-02 02:14:45.950 | INFO     | trainer:train_loop:171 - Epoch: [95/ 100] | Train loss: [0.04076180413365364]
2023-06-02 02:20:00.697 | INFO     | trainer:train_loop:171 - Epoch: [96/ 100] | Train loss: [0.0418535138964653]
2023-06-02 02:25:11.851 | INFO     | trainer:train_loop:171 - Epoch: [97/ 100] | Train loss: [0.04138939063251019]
2023-06-02 02:30:26.016 | INFO     | trainer:train_loop:171 - Epoch: [98/ 100] | Train loss: [0.039856254354119304]
2023-06-02 02:35:38.504 | INFO     | trainer:train_loop:171 - Epoch: [99/ 100] | Train loss: [0.03941945038735867]
2023-06-02 02:40:50.603 | INFO     | trainer:train_loop:171 - Epoch: [100/ 100] | Train loss: [0.04032237240672112]
2023-06-02 02:40:50.971 | INFO     | trainer:train_loop:183 - [Saving Snapshot:]/root/neo_code_reco/configs/checkpoint/MiT-B3-FaPNHead_100.pth
2023-06-02 02:40:50.972 | INFO     | trainer:train_loop:192 - Training cost: 31218.15607780218seconds
