2023-06-05 09:55:54.181 | INFO     | __main__:main:57 - Load config from configs/neo_small.yaml
2023-06-05 09:55:54.181 | INFO     | __main__:main:58 - {'dataset': {'data_path': '/root/neo_code_reco/bkai-igh-neopolyp', 'train_data_path': ['/root/neo_code_reco/bkai-igh-neopolyp'], 'test_data_path': ['/root/neo_code/bkai-igh-neopolyp/test/test'], 'val_data_path': ['/root/neo_code_reco/bkai-igh-neopolyp']}, 'model': {'num_classes': 3, 'save_dir': '/root/neo_code_reco_mb/configs/checkpoint_0406', 'backbone': 'MiT-B3', 'head': 'FaPNHead', 'pretrained': 'mit_b3.pth'}, 'optimizer': {'name': 'adam', 'lr': 0.0001, 'clip': 0.5, 'scheduler': 'cosine_warmup', 'loss': 'multi_structure_loss'}, 'dev': 'cuda', 'train': {'start_from': 0, 'save_from': 99, 'num_epochs': 100, 'num_warmup_epoch': 8, 'is_val': False, 'size_rates': [0.75, 1, 1.25], 'dataloader': {'batchsize': 8, 'img_size': 384, 'shuffle': True, 'num_workers': 4, 'pin_memory': True, 'drop_last': True}, 'amp': False, 'ddp': False, 'augment': {'prob': 1, 'Flip_prob': 0.5, 'HueSaturationValue_prob': 0.5, 'RandomBrightnessContrast_prob': 0.5, 'crop_prob': 0.0, 'randomrotate90_prob': 0.5, 'ColorJitter_prob': 0.5}, 'augment_weak': {'prob': 1, 'Flip_prob': 0.5}}, 'val': {'dataloader': {'batchsize': 8, 'img_size': 384, 'shuffle': True, 'num_workers': 4, 'pin_memory': True, 'drop_last': False}}, 'test': {'dev': 'cuda', 'visualize': True, 'visualize_dir': '/root/neo_code_reco/neo_visualize', 'vis_x': 180, 'vis_overwrite': False, 'checkpoint_dir': '/root/neo_code_reco/configs/checkpoint_0406/MiT-B3-FaPNHead_100_teacher.pth', 'dataloader': {'batchsize': 1, 'img_size': 384, 'shuffle': True, 'num_workers': 4, 'pin_memory': True, 'drop_last': False}, 'augment': {'prob': 1, 'Flip_prob': 0, 'HueSaturationValue_prob': 0, 'RandomBrightnessContrast_prob': 0, 'crop_prob': 0, 'randomrotate90_prob': 0, 'elastictransform_prob': 0, 'gridistortion_prob': 0, 'opticaldistortion_prob': 0, 'verticalflip_prob': 0, 'horizontalflip_prob': 0, 'randomgamma_prob': 0, 'CoarseDropout_prob': 0, 'RGBShift_prob': 0, 'MotionBlur_prob': 0, 'MedianBlur_prob': 0, 'GaussianBlur_prob': 0, 'GaussNoise_prob': 0, 'ChannelShuffle_prob': 0}}}
2023-06-05 09:55:54.181 | INFO     | __main__:main:59 - Getting datapath
2023-06-05 09:55:54.190 | INFO     | __main__:main:74 - There are 1000 images to train
2023-06-05 09:55:54.190 | INFO     | __main__:main:93 - Train model with no valid dataset
2023-06-05 09:55:54.190 | INFO     | __main__:main:95 - Loading data
2023-06-05 09:55:54.601 | INFO     | __main__:main:112 - 125 batches to train
2023-06-05 09:55:54.602 | INFO     | __main__:main:125 - Loading model
2023-06-05 09:55:54.602 | INFO     | __main__:main:146 - Loading checkpoint from mit_b3.pth ...
2023-06-05 09:56:00.747 | INFO     | __main__:main:190 - Training with FP32 ...
2023-06-05 10:01:17.695 | INFO     | trainer:train_loop:182 - Epoch: [1/ 100] | Train loss: [1.6045944728851318]
2023-06-05 10:06:33.968 | INFO     | trainer:train_loop:182 - Epoch: [2/ 100] | Train loss: [0.6802410101890564]
2023-06-05 10:11:50.572 | INFO     | trainer:train_loop:182 - Epoch: [3/ 100] | Train loss: [0.6145463693141937]
2023-06-05 10:17:08.510 | INFO     | trainer:train_loop:182 - Epoch: [4/ 100] | Train loss: [0.5521060442924499]
2023-06-05 10:22:25.480 | INFO     | trainer:train_loop:182 - Epoch: [5/ 100] | Train loss: [0.3713412905931473]
2023-06-05 10:27:45.221 | INFO     | trainer:train_loop:182 - Epoch: [6/ 100] | Train loss: [0.34974856024980544]
2023-06-05 10:33:06.480 | INFO     | trainer:train_loop:182 - Epoch: [7/ 100] | Train loss: [0.31578835761547086]
2023-06-05 10:38:27.593 | INFO     | trainer:train_loop:182 - Epoch: [8/ 100] | Train loss: [0.28123116147518157]
2023-06-05 10:43:48.796 | INFO     | trainer:train_loop:182 - Epoch: [9/ 100] | Train loss: [0.26917374262213706]
2023-06-05 10:49:09.597 | INFO     | trainer:train_loop:182 - Epoch: [10/ 100] | Train loss: [0.23156584030389785]
2023-06-05 10:54:29.937 | INFO     | trainer:train_loop:182 - Epoch: [11/ 100] | Train loss: [0.2293281261920929]
2023-06-05 10:59:49.531 | INFO     | trainer:train_loop:182 - Epoch: [12/ 100] | Train loss: [0.2192952968478203]
2023-06-05 11:05:08.584 | INFO     | trainer:train_loop:182 - Epoch: [13/ 100] | Train loss: [0.21108561858534813]
2023-06-05 11:10:27.509 | INFO     | trainer:train_loop:182 - Epoch: [14/ 100] | Train loss: [0.20631597831845283]
2023-06-05 11:15:47.952 | INFO     | trainer:train_loop:182 - Epoch: [15/ 100] | Train loss: [0.21001043313741685]
2023-06-05 11:21:08.327 | INFO     | trainer:train_loop:182 - Epoch: [16/ 100] | Train loss: [0.1924106856584549]
2023-06-05 11:26:28.509 | INFO     | trainer:train_loop:182 - Epoch: [17/ 100] | Train loss: [0.20931147992610932]
2023-06-05 11:31:48.849 | INFO     | trainer:train_loop:182 - Epoch: [18/ 100] | Train loss: [0.19821570703387262]
2023-06-05 11:37:08.743 | INFO     | trainer:train_loop:182 - Epoch: [19/ 100] | Train loss: [0.20160619750618936]
2023-06-05 11:42:27.606 | INFO     | trainer:train_loop:182 - Epoch: [20/ 100] | Train loss: [0.2025717750787735]
2023-06-05 11:47:45.426 | INFO     | trainer:train_loop:182 - Epoch: [21/ 100] | Train loss: [0.24026229318976403]
2023-06-05 11:53:05.225 | INFO     | trainer:train_loop:182 - Epoch: [22/ 100] | Train loss: [0.17177213871479036]
2023-06-05 11:58:25.085 | INFO     | trainer:train_loop:182 - Epoch: [23/ 100] | Train loss: [0.16817275446653365]
2023-06-05 12:03:46.653 | INFO     | trainer:train_loop:182 - Epoch: [24/ 100] | Train loss: [0.16898369899392127]
2023-06-05 12:09:06.892 | INFO     | trainer:train_loop:182 - Epoch: [25/ 100] | Train loss: [0.1693491871356964]
2023-06-05 12:14:26.273 | INFO     | trainer:train_loop:182 - Epoch: [26/ 100] | Train loss: [0.15509752947092056]
2023-06-05 12:19:44.743 | INFO     | trainer:train_loop:182 - Epoch: [27/ 100] | Train loss: [0.15641709131002426]
2023-06-05 12:25:04.844 | INFO     | trainer:train_loop:182 - Epoch: [28/ 100] | Train loss: [0.14879128375649453]
2023-06-05 12:30:25.663 | INFO     | trainer:train_loop:182 - Epoch: [29/ 100] | Train loss: [0.15219366297125816]
2023-06-05 12:35:44.048 | INFO     | trainer:train_loop:182 - Epoch: [30/ 100] | Train loss: [0.1371990337818861]
2023-06-05 12:41:04.781 | INFO     | trainer:train_loop:182 - Epoch: [31/ 100] | Train loss: [0.1614550485163927]
2023-06-05 12:46:25.526 | INFO     | trainer:train_loop:182 - Epoch: [32/ 100] | Train loss: [0.15413691768050194]
2023-06-05 12:51:43.306 | INFO     | trainer:train_loop:182 - Epoch: [33/ 100] | Train loss: [0.1547486900985241]
2023-06-05 12:57:01.916 | INFO     | trainer:train_loop:182 - Epoch: [34/ 100] | Train loss: [0.15180865943431854]
2023-06-05 13:02:23.034 | INFO     | trainer:train_loop:182 - Epoch: [35/ 100] | Train loss: [0.15629123847186566]
2023-06-05 13:07:43.478 | INFO     | trainer:train_loop:182 - Epoch: [36/ 100] | Train loss: [0.1494300182312727]
2023-06-05 13:13:00.886 | INFO     | trainer:train_loop:182 - Epoch: [37/ 100] | Train loss: [0.17341538065671921]
2023-06-05 13:18:21.004 | INFO     | trainer:train_loop:182 - Epoch: [38/ 100] | Train loss: [0.14907388515770437]
2023-06-05 13:23:40.441 | INFO     | trainer:train_loop:182 - Epoch: [39/ 100] | Train loss: [0.13327643579244614]
2023-06-05 13:29:02.316 | INFO     | trainer:train_loop:182 - Epoch: [40/ 100] | Train loss: [0.1401163308918476]
2023-06-05 13:34:24.034 | INFO     | trainer:train_loop:182 - Epoch: [41/ 100] | Train loss: [0.12875573614239694]
2023-06-05 13:39:42.593 | INFO     | trainer:train_loop:182 - Epoch: [42/ 100] | Train loss: [0.180929525077343]
2023-06-05 13:45:02.874 | INFO     | trainer:train_loop:182 - Epoch: [43/ 100] | Train loss: [0.1588772093653679]
2023-06-05 13:50:19.933 | INFO     | trainer:train_loop:182 - Epoch: [44/ 100] | Train loss: [0.14809525394439696]
2023-06-05 13:55:41.744 | INFO     | trainer:train_loop:182 - Epoch: [45/ 100] | Train loss: [0.1339986753165722]
2023-06-05 14:01:01.519 | INFO     | trainer:train_loop:182 - Epoch: [46/ 100] | Train loss: [0.12606045772135258]
2023-06-05 14:06:20.331 | INFO     | trainer:train_loop:182 - Epoch: [47/ 100] | Train loss: [0.10596357896924019]
2023-06-05 14:11:40.933 | INFO     | trainer:train_loop:182 - Epoch: [48/ 100] | Train loss: [0.10820607186853885]
2023-06-05 14:17:02.900 | INFO     | trainer:train_loop:182 - Epoch: [49/ 100] | Train loss: [0.1358468846231699]
2023-06-05 14:22:24.073 | INFO     | trainer:train_loop:182 - Epoch: [50/ 100] | Train loss: [0.13298517513275146]
2023-06-05 14:27:44.840 | INFO     | trainer:train_loop:182 - Epoch: [51/ 100] | Train loss: [0.1229653899371624]
2023-06-05 14:33:06.857 | INFO     | trainer:train_loop:182 - Epoch: [52/ 100] | Train loss: [0.12867555524408816]
2023-06-05 14:38:26.265 | INFO     | trainer:train_loop:182 - Epoch: [53/ 100] | Train loss: [0.11275061362981796]
2023-06-05 14:43:47.410 | INFO     | trainer:train_loop:182 - Epoch: [54/ 100] | Train loss: [0.10595922119915485]
2023-06-05 14:49:07.994 | INFO     | trainer:train_loop:182 - Epoch: [55/ 100] | Train loss: [0.09903443719446658]
2023-06-05 14:54:26.904 | INFO     | trainer:train_loop:182 - Epoch: [56/ 100] | Train loss: [0.08326302070915699]
2023-06-05 14:59:47.124 | INFO     | trainer:train_loop:182 - Epoch: [57/ 100] | Train loss: [0.0898574724048376]
2023-06-05 15:05:06.355 | INFO     | trainer:train_loop:182 - Epoch: [58/ 100] | Train loss: [0.09247202260792256]
2023-06-05 15:10:27.635 | INFO     | trainer:train_loop:182 - Epoch: [59/ 100] | Train loss: [0.08918311113119125]
2023-06-05 15:15:46.671 | INFO     | trainer:train_loop:182 - Epoch: [60/ 100] | Train loss: [0.08394514982402325]
2023-06-05 15:21:08.827 | INFO     | trainer:train_loop:182 - Epoch: [61/ 100] | Train loss: [0.08315273062884808]
2023-06-05 15:26:30.232 | INFO     | trainer:train_loop:182 - Epoch: [62/ 100] | Train loss: [0.08881581619381905]
2023-06-05 15:31:50.828 | INFO     | trainer:train_loop:182 - Epoch: [63/ 100] | Train loss: [0.08735801337659359]
2023-06-05 15:37:12.097 | INFO     | trainer:train_loop:182 - Epoch: [64/ 100] | Train loss: [0.07811494873464107]
2023-06-05 15:42:33.880 | INFO     | trainer:train_loop:182 - Epoch: [65/ 100] | Train loss: [0.08011518275737763]
2023-06-05 15:47:56.521 | INFO     | trainer:train_loop:182 - Epoch: [66/ 100] | Train loss: [0.07507847154140472]
2023-06-05 15:53:15.835 | INFO     | trainer:train_loop:182 - Epoch: [67/ 100] | Train loss: [0.07847900402545929]
2023-06-05 15:58:35.082 | INFO     | trainer:train_loop:182 - Epoch: [68/ 100] | Train loss: [0.07106395311653614]
2023-06-05 16:03:57.507 | INFO     | trainer:train_loop:182 - Epoch: [69/ 100] | Train loss: [0.06551358968019486]
2023-06-05 16:09:19.202 | INFO     | trainer:train_loop:182 - Epoch: [70/ 100] | Train loss: [0.06774746909737588]
2023-06-05 16:14:39.696 | INFO     | trainer:train_loop:182 - Epoch: [71/ 100] | Train loss: [0.06437101139128208]
2023-06-05 16:19:57.913 | INFO     | trainer:train_loop:182 - Epoch: [72/ 100] | Train loss: [0.0631026117503643]
2023-06-05 16:25:17.200 | INFO     | trainer:train_loop:182 - Epoch: [73/ 100] | Train loss: [0.060845882445573804]
2023-06-05 16:30:39.267 | INFO     | trainer:train_loop:182 - Epoch: [74/ 100] | Train loss: [0.06491776591539383]
2023-06-05 16:36:00.212 | INFO     | trainer:train_loop:182 - Epoch: [75/ 100] | Train loss: [0.06712844771146774]
2023-06-05 16:41:21.993 | INFO     | trainer:train_loop:182 - Epoch: [76/ 100] | Train loss: [0.05679207794368267]
2023-06-05 16:46:42.042 | INFO     | trainer:train_loop:182 - Epoch: [77/ 100] | Train loss: [0.05747247250378132]
2023-06-05 16:52:04.855 | INFO     | trainer:train_loop:182 - Epoch: [78/ 100] | Train loss: [0.06468234132230281]
2023-06-05 16:57:24.704 | INFO     | trainer:train_loop:182 - Epoch: [79/ 100] | Train loss: [0.05296556727588177]
2023-06-05 17:02:46.624 | INFO     | trainer:train_loop:182 - Epoch: [80/ 100] | Train loss: [0.05652333696186543]
2023-06-05 17:08:06.264 | INFO     | trainer:train_loop:182 - Epoch: [81/ 100] | Train loss: [0.0533628938049078]
2023-06-05 17:13:26.621 | INFO     | trainer:train_loop:182 - Epoch: [82/ 100] | Train loss: [0.05370063941180706]
2023-06-05 17:18:48.482 | INFO     | trainer:train_loop:182 - Epoch: [83/ 100] | Train loss: [0.05404158961772919]
2023-06-05 17:24:08.900 | INFO     | trainer:train_loop:182 - Epoch: [84/ 100] | Train loss: [0.05359322825074196]
2023-06-05 17:29:30.909 | INFO     | trainer:train_loop:182 - Epoch: [85/ 100] | Train loss: [0.0460117281973362]
2023-06-05 17:34:51.916 | INFO     | trainer:train_loop:182 - Epoch: [86/ 100] | Train loss: [0.04804804074764252]
2023-06-05 17:40:14.250 | INFO     | trainer:train_loop:182 - Epoch: [87/ 100] | Train loss: [0.04569704666733742]
2023-06-05 17:45:34.969 | INFO     | trainer:train_loop:182 - Epoch: [88/ 100] | Train loss: [0.04574166460335255]
2023-06-05 17:50:57.051 | INFO     | trainer:train_loop:182 - Epoch: [89/ 100] | Train loss: [0.04634984815120697]
2023-06-05 17:56:17.145 | INFO     | trainer:train_loop:182 - Epoch: [90/ 100] | Train loss: [0.04677919229865074]
2023-06-05 18:01:38.631 | INFO     | trainer:train_loop:182 - Epoch: [91/ 100] | Train loss: [0.0429281318038702]
2023-06-05 18:06:56.799 | INFO     | trainer:train_loop:182 - Epoch: [92/ 100] | Train loss: [0.049151948049664496]
2023-06-05 18:12:17.542 | INFO     | trainer:train_loop:182 - Epoch: [93/ 100] | Train loss: [0.04524149321019649]
2023-06-05 18:17:37.332 | INFO     | trainer:train_loop:182 - Epoch: [94/ 100] | Train loss: [0.04747358570992947]
2023-06-05 18:22:58.282 | INFO     | trainer:train_loop:182 - Epoch: [95/ 100] | Train loss: [0.043278129398822786]
2023-06-05 18:28:18.098 | INFO     | trainer:train_loop:182 - Epoch: [96/ 100] | Train loss: [0.04584892229735851]
2023-06-05 18:33:37.326 | INFO     | trainer:train_loop:182 - Epoch: [97/ 100] | Train loss: [0.04176815260946751]
2023-06-05 18:38:56.594 | INFO     | trainer:train_loop:182 - Epoch: [98/ 100] | Train loss: [0.04467232698202133]
2023-06-05 18:44:15.005 | INFO     | trainer:train_loop:182 - Epoch: [99/ 100] | Train loss: [0.03920361568033695]
2023-06-05 18:49:38.442 | INFO     | trainer:train_loop:182 - Epoch: [100/ 100] | Train loss: [0.042920636385679244]
2023-06-05 18:49:39.403 | INFO     | trainer:train_loop:203 - [Saving Snapshot:]/root/neo_code_reco_mb/configs/checkpoint_0406/MiT-B3-FaPNHead_100.pth
2023-06-05 18:49:39.405 | INFO     | trainer:train_loop:212 - Training cost: 32016.99438841641seconds
